{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='rdw_top'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add extra information from RDW open data\n",
    "\n",
    "Query to the open data dataset of the RDW.\n",
    "\n",
    "\n",
    "1. <a href=\"#rdw_registrations\">Registration numbers</a>  \n",
    "    Apis with registration as key\n",
    "2. <a href=\"#rdw_confcodes\">Conformity codes</a>  \n",
    "    Cars get a conformity code when certified.\n",
    "3. <a href=\"#rdw_other_apis\">Other APIs</a>  \n",
    "    It may take a while (10 min) to query all conformity codes individually.\n",
    "4. <a href=\"#rdw_ovi\">Closed data</a>  \n",
    "    Get closed data from RDW website. This also takes a while because of time out enforced by website. Use config to disable.\n",
    "5. <a href=\"#rdw_merge\">Merge results</a>  \n",
    "    Combine all dataframes and save\n",
    "\n",
    "- - - - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbconvert_instruction:remove_all_outputs"
    ]
   },
   "outputs": [],
   "source": [
    "import drz_config\n",
    "cfg = drz_config.read_config()\n",
    "DATE = cfg['DATE']\n",
    "VERBOSE = cfg['VERBOSE']\n",
    "OPBOD = cfg['OPBOD']\n",
    "CLOSEDDATA = cfg['CLOSEDDATA']\n",
    "closed_data_fields = cfg['closed_data_fields']\n",
    "SKIPSAVE = cfg['SKIPSAVE']\n",
    "TAG_RM_ALL = \"nbconvert_instruction:remove_all_outputs\" # tag to remove cell output to reduce \"diff\" output when comitting\n",
    "\n",
    "QUICK_MERGE = False # check if rdw data already exist (ran when auction was still open)\n",
    "\n",
    "\n",
    "if VERBOSE > 0:\n",
    "    display(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modules and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re \n",
    "import os\n",
    "# to keep api key hidden import this from sub dir\n",
    "import assets.hidden_api_keys as hidden_api_keys\n",
    "from time import sleep\n",
    "import urllib\n",
    "\n",
    "# base url\n",
    "apiurl = 'https://opendata.rdw.nl/resource/m9d7-ebf2.json?$$app_token=' + hidden_api_keys.socrata_apptoken + '&'\n",
    "\n",
    "def get_json_from_api(url,reg,c=0):\n",
    "    \n",
    "    '''Get json object from api'''\n",
    "    \n",
    "    import time\n",
    "\n",
    "    c+=1\n",
    "    try:\n",
    "        df=pd.read_json(url + 'kenteken=' + reg.replace('-','').upper()).to_dict()\n",
    "    except:\n",
    "        if c > 10:\n",
    "            print(url,reg)\n",
    "            raise \n",
    "        else:\n",
    "            print('pause 2 sec and try again!')\n",
    "            time.sleep(2)\n",
    "            df = get_json_from_api(url,reg,c)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "# get_json_from_api(apiurl,'61-sf-FG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load auction results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbconvert_instruction:remove_all_outputs"
    ]
   },
   "outputs": [],
   "source": [
    "if OPBOD:\n",
    "    file_name = '../../../python-nb/data/drz-data-opbod-{}.pkl'.format(DATE)\n",
    "else:\n",
    "    file_name = '../data/drz-data-{}.pkl'.format(DATE)\n",
    "\n",
    "if not os.path.isfile(file_name):\n",
    "    # see if -without price- exists\n",
    "    NO_PRICE = True\n",
    "    file_name = file_name.replace('.pkl', '-without-price.pkl')\n",
    "else:\n",
    "    NO_PRICE = False\n",
    "\n",
    "print(file_name)\n",
    "drz = pd.read_pickle(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load existing RDW data and merge with price\n",
    "file_name = f'../data/rdw-data-{DATE}.pkl'\n",
    "file_name = file_name.replace('.pkl', '-without-price.pkl')\n",
    "if os.path.isfile(file_name) & QUICK_MERGE:\n",
    "    print(file_name)\n",
    "    rdw = pd.read_pickle(file_name)\n",
    "    \n",
    "    # add price\n",
    "    rdw.update(drz.Price)\n",
    "\n",
    "    # save\n",
    "    out = rdw.copy()\n",
    "    file_name = file_name.replace('-without-price.pkl','.pkl')\n",
    "    if (SKIPSAVE==False) and (not(os.path.isfile(file_name))):\n",
    "        print(file_name)\n",
    "        out.to_pickle(file_name)\n",
    "    else:\n",
    "        print(f'Skip. {file_name} exists or saving is disabled in settings.')\n",
    "        \n",
    "    assert False, \"Stop running. Everything is done\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect registrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbconvert_instruction:remove_all_outputs"
    ]
   },
   "outputs": [],
   "source": [
    "# see what lots have a Dutch registration (license number).\n",
    "hasReg = (~drz.Reg.isnull()) & (drz.Reg != 'onbekend') & (drz.Reg != '') & (~drz.LotType.isin([\n",
    "    'Vaartuig',\n",
    "    'Jetski',\n",
    "    'Sloep',\n",
    "    'Speedboot',\n",
    "    'Vaartuig (Type onbekend)',\n",
    "    'Motorvaartuig met opbouw (Pleziervaartuig)',\n",
    "]))\n",
    "\n",
    "print('nr. of registrations:',sum(hasReg))\n",
    "\n",
    "# # make a copy and add info\n",
    "# rdw = drz.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_url(api_url, keys, token=hidden_api_keys.socrata_apptoken, query_field='kenteken'):\n",
    "    '''construct query url'''\n",
    "\n",
    "    import urllib\n",
    "\n",
    "    # First part\n",
    "    q = api_url + '?$$app_token=' + token + '&'\n",
    "\n",
    "    # convert list to string\n",
    "    id_list = ''.join([\"'{}', \".format(k) for k in keys])\n",
    "    id_list = id_list[0:-2] # remove trailing ', '\n",
    "    \n",
    "    # add escaped soql\n",
    "    soql = '$where=' + urllib.parse.quote(query_field + ' in (' + id_list + ')')\n",
    "    q += soql\n",
    "    \n",
    "    # See if field is available\n",
    "    accepted_fields = eval(urllib.request.urlopen(api_url).headers.get('X-SODA2-Fields'))\n",
    "    if query_field not in accepted_fields:\n",
    "        raise ValueError(f'<{query_field}> not allowed as SODA2 field in {api_url}.\\n\\tAccepted are: ' + ', '.join(accepted_fields))\n",
    "    \n",
    "    return q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create list of dataframes with different api results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbconvert_instruction:remove_all_outputs"
    ]
   },
   "outputs": [],
   "source": [
    "# empty dictionary\n",
    "rdw_per_reg = dict()\n",
    "\n",
    "# first element of dict is registrations\n",
    "key = 'registations'\n",
    "rdw_per_reg[key] = drz.loc[hasReg,['Reg', 'LotType']].copy() # copy from drz\n",
    "rdw_per_reg[key]['kenteken'] = rdw_per_reg[key].Reg.apply(lambda r: r.replace('-','').upper())\n",
    "rdw_per_reg[key].index.name = 'lot_index'\n",
    "rdw_per_reg[key] = rdw_per_reg[key].reset_index().set_index('kenteken')\n",
    "display(rdw_per_reg[key].reset_index().set_index(['LotType', 'kenteken']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1><a href=\"#rdw_top\">^</a></H1><a id='rdw_registrations'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main apis\n",
    "\n",
    "The main api: `api_gekentekende_voertuigen` points to subsequent apis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbconvert_instruction:remove_all_outputs"
    ]
   },
   "outputs": [],
   "source": [
    "# Assess these registrations\n",
    "regs = rdw_per_reg['registations'].Reg.values\n",
    "regs = [r.replace('-','').upper() for r in regs]\n",
    "print(len(regs),'registrations in this set')\n",
    "\n",
    "# Do main api first to get other possible apis\n",
    "api_name = 'api_gekentekende_voertuigen'\n",
    "api_url = 'https://opendata.rdw.nl/resource/m9d7-ebf2.json'\n",
    "\n",
    "# Query api\n",
    "key = re.sub('^api_','', api_name) # store with this key\n",
    "q = get_query_url(api_url,regs)\n",
    "rdw_per_reg[key] = pd.read_json(q)\n",
    "rdw_per_reg[key].set_index('kenteken', inplace=True)\n",
    "\n",
    "print(api_name, end=': ')\n",
    "display(rdw_per_reg[key])\n",
    "\n",
    "# Query other available apis\n",
    "for api_name in [c for c in rdw_per_reg['gekentekende_voertuigen'].columns if c.startswith('api')]:\n",
    "    print(api_name, end=': ')\n",
    "    key = re.sub('^api_','',api_name)\n",
    "    for api_url in rdw_per_reg['gekentekende_voertuigen'][api_name].unique():\n",
    "        print(api_url)\n",
    "        # query the web\n",
    "        q = get_query_url(api_url,regs)\n",
    "        df0 = pd.read_json(q)\n",
    "        # name of index\n",
    "        df0.columns.name = api_name\n",
    "\n",
    "        # query should return 'kenteken', make it the index\n",
    "        if df0.shape[0] != 0:\n",
    "            df0.set_index('kenteken', inplace=True)\n",
    "            \n",
    "        # Some apis return multiple values. Pivot around index number (\"volgnummer\")\n",
    "        if api_name == 'api_gekentekende_voertuigen_assen':\n",
    "            df0 = pd.pivot(df0, columns='as_nummer')\n",
    "\n",
    "        elif api_name == 'api_gekentekende_voertuigen_brandstof':\n",
    "            df0 = pd.pivot(df0, columns='brandstof_volgnummer')\n",
    "\n",
    "        elif api_name == 'api_gekentekende_voertuigen_carrosserie':\n",
    "            df0 = pd.pivot(df0, columns='carrosserie_volgnummer')\n",
    "\n",
    "        elif api_name == 'api_gekentekende_voertuigen_carrosserie_specifiek':\n",
    "            df0 = pd.pivot(df0, columns='carrosserie_voertuig_nummer_code_volgnummer')\n",
    "\n",
    "        # squeeze multi index\n",
    "        one_level = [\n",
    "            re.sub('^api_gekentekende_voertuigen_','',api_name) + '_' + '_'.join(\n",
    "                [str(c) if type(c)==int else c for c in l]\n",
    "            ) for l in df0.columns\n",
    "        ]\n",
    "        df0.columns = one_level\n",
    "\n",
    "        # add to list\n",
    "        display(df0.tail(3))\n",
    "        print(df0.shape)\n",
    "        rdw_per_reg[key]=df0\n",
    "\n",
    "# Merge dataframes from different apis\n",
    "df_regs = pd.concat(rdw_per_reg.values(), axis='columns', sort=False)\n",
    "# add timestamp\n",
    "df_regs['TimeStamp'] = pd.to_datetime('now').strftime('%Y%m%d')\n",
    "# set lot id as index\n",
    "df_regs.index.name = 'kenteken'\n",
    "df_regs = df_regs.reset_index().set_index('lot_index')\n",
    "display(df_regs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1><a href=\"#rdw_top\">^</a></H1><a id='rdw_confcodes'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conformity codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbconvert_instruction:remove_all_outputs"
    ]
   },
   "outputs": [],
   "source": [
    "# empty dict\n",
    "rdw_per_confcode = dict()\n",
    "# Conformity codes have sub-divisions. Four fields make a super key\n",
    "key = 'conformity_codes'\n",
    "rdw_per_confcode[key] = rdw_per_reg['gekentekende_voertuigen'][[\n",
    "    'typegoedkeuringsnummer', \n",
    "    'uitvoering', \n",
    "    'variant', \n",
    "    'volgnummer_wijziging_eu_typegoedkeuring'\n",
    "]].dropna().drop_duplicates()\n",
    "rdw_per_confcode[key].reset_index(drop=True, inplace=True)\n",
    "print(len(rdw_per_confcode[key]),'conformity codes in this set')\n",
    "\n",
    "display(rdw_per_confcode[key])\n",
    "print('count unique')\n",
    "display(\\\n",
    "    rdw_per_reg['gekentekende_voertuigen'].loc[:, rdw_per_confcode[key].columns]\\\n",
    "    .reset_index()\\\n",
    "    .groupby([rdw_per_confcode[key].columns[0]])\\\n",
    "    .nunique()\\\n",
    "    .replace(1,np.NaN)\\\n",
    "    .dropna(how='all')\\\n",
    "    .fillna(1)\\\n",
    "    .astype(int)\\\n",
    "    .sort_values(by='kenteken', ascending=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbconvert_instruction:remove_all_outputs"
    ]
   },
   "outputs": [],
   "source": [
    "# do conformity api and again get other possible apis\n",
    "api_name = 'api_eeg_voertuigtypegoedkeuring'\n",
    "api_url = 'https://opendata.rdw.nl/resource/55kv-xf7m.json'\n",
    "\n",
    "# Query api\n",
    "key = re.sub('^api_','', api_name) # store with this key\n",
    "q = get_query_url(\n",
    "    api_url, \n",
    "    rdw_per_confcode['conformity_codes'].typegoedkeuringsnummer.unique(), # Use long (year with century) version of conformity code\n",
    "    query_field='typegoedkeuringsnummer'\n",
    ")\n",
    "rdw_per_confcode[key] = pd.read_json(q)\n",
    "# more than one conformity code?\n",
    "assert not (rdw_per_confcode[key].groupby('typegoedkeuringsnummer')['typegoedkeuringsnummer'].count() > 1).any()\n",
    "rdw_per_confcode[key].set_index('typegoedkeuringsnummer', inplace=True)\n",
    "\n",
    "# add slightly different keys (year has no century)\n",
    "rdw_per_confcode['conformity_codes'] = rdw_per_confcode['conformity_codes'].merge(\n",
    "    rdw_per_confcode['eeg_voertuigtypegoedkeuring'].eu_type_goedkeuringssleutel, \n",
    "    how='left', \n",
    "    left_on='typegoedkeuringsnummer', \n",
    "    right_index=True\n",
    ")\n",
    "\n",
    "print(api_name, end=': ')\n",
    "display(rdw_per_confcode[key])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1><a href=\"#rdw_top\">^</a></H1><a id='rdw_other_apis'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other apis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbconvert_instruction:remove_all_outputs"
    ]
   },
   "outputs": [],
   "source": [
    "# query other available apis\n",
    "api_list = [c for c in rdw_per_confcode['eeg_voertuigtypegoedkeuring'].columns if c.startswith('api')]\n",
    "for api_name in api_list:\n",
    "    print(api_name, end=''.join(['|' if api_name==list_element else '.'  for list_element in api_list]))\n",
    "    key = re.sub('^api_','',api_name)\n",
    "    for api_url in rdw_per_confcode['eeg_voertuigtypegoedkeuring'][api_name].unique():\n",
    "        \n",
    "        # reformat url\n",
    "        M=re.search('https://opendata.rdw.nl/.*/([a-z0-9]{4}-[a-z0-9]{4})$', api_url)\n",
    "        api_url = 'https://opendata.rdw.nl/resource/{}.json'.format(M[1])\n",
    "        print(api_url)\n",
    "       \n",
    "        # query the web\n",
    "        # unfortunately this needs to be done one by one, because conformity code is not unique                   \n",
    "        df0 = pd.DataFrame()\n",
    "        for ix, row in rdw_per_confcode['conformity_codes'].iterrows():\n",
    "            q = api_url\n",
    "            q += '?$$app_token=' + hidden_api_keys.socrata_apptoken \n",
    "            q += '&{}=\\'{}\\''.format('eu_type_goedkeuringssleutel', urllib.parse.quote(row.eu_type_goedkeuringssleutel))\n",
    "            q += '&{}=\\'{}\\''.format('eeg_uitvoeringscode', urllib.parse.quote(row.uitvoering))\n",
    "            q += '&{}=\\'{}\\''.format('eeg_variantcode', urllib.parse.quote(row.variant))\n",
    "            q += '&{}={:.0f}'.format('uitvoering_wijzigingsnummer', row.volgnummer_wijziging_eu_typegoedkeuring)\n",
    "                \n",
    "            n_try = 0\n",
    "            OK = False\n",
    "            while (n_try < 10) & (not OK):\n",
    "                try:\n",
    "                    res = pd.read_json(q)\n",
    "                    OK = True\n",
    "                    n_try = 0\n",
    "                except:\n",
    "                    n_try +=1\n",
    "                    sleep(10)\n",
    "                if n_try == 10:\n",
    "                    raise\n",
    "\n",
    "            if len(res) == 0:\n",
    "                continue\n",
    "\n",
    "            # matching data type with 'codes' for merging\n",
    "            res.eu_type_goedkeuringssleutel = res.eu_type_goedkeuringssleutel.astype(str)\n",
    "            res.eeg_uitvoeringscode = res.eeg_uitvoeringscode.astype(str)\n",
    "            res.eeg_variantcode = res.eeg_variantcode.astype(str)\n",
    "            res.uitvoering_wijzigingsnummer = res.uitvoering_wijzigingsnummer.astype(float)\n",
    "            res.set_index([\n",
    "                'eu_type_goedkeuringssleutel', \n",
    "                'eeg_uitvoeringscode', \n",
    "                'eeg_variantcode', \n",
    "                'uitvoering_wijzigingsnummer'\n",
    "            ], inplace=True)\n",
    "                \n",
    "                \n",
    "            # Api specific modifiers\n",
    "            if api_name == 'api_as_gegevens_eeg_uitvoering':               \n",
    "                piv = res.pivot(columns='asnummer')\n",
    "                one_level = [\n",
    "                            re.sub('^api_','', re.sub('_eeg_uitvoering$','',api_name)) + '_' + '_'.join(\n",
    "                                [str(c) if type(c)==int else c for c in l]\n",
    "                            ) for l in piv.columns\n",
    "                        ]\n",
    "                piv.columns = one_level\n",
    "                df0 = pd.concat([df0, piv], sort=False)                \n",
    "            elif api_name == 'api_handelsbenaming_uitvoering':                \n",
    "                piv = res.pivot(columns='volgnummer')\n",
    "                one_level = [\n",
    "                            re.sub('^api_','', re.sub('_eeg_uitvoering$','',api_name)) + '_' + '_'.join(\n",
    "                                [str(c) if type(c)==int else c for c in l]\n",
    "                            ) for l in piv.columns\n",
    "                        ]\n",
    "                piv.columns = one_level\n",
    "                df0 = pd.concat([df0, piv], sort=False)\n",
    "            elif api_name == 'api_carrosserie_uitvoering':                \n",
    "                piv = res.pivot(columns='carrosserie_volgnummer')\n",
    "                one_level = [\n",
    "                            re.sub('^api_','', re.sub('_eeg_uitvoering$','',api_name)) + '_' + '_'.join(\n",
    "                                [str(c) if type(c)==int else c for c in l]\n",
    "                            ) for l in piv.columns\n",
    "                        ]\n",
    "                piv.columns = one_level\n",
    "                df0 = pd.concat([df0, piv], sort=False)\n",
    "            elif api_name == 'api_plaatsaanduiding_uitvoering':\n",
    "                piv = res.pivot(columns='plaats_aanduiding_volgnummer')\n",
    "                one_level = [\n",
    "                            re.sub('^api_','', re.sub('_eeg_uitvoering$','',api_name)) + '_' + '_'.join(\n",
    "                                [str(c) if type(c)==int else c for c in l]\n",
    "                            ) for l in piv.columns\n",
    "                        ]\n",
    "                piv.columns = one_level\n",
    "                df0 = pd.concat([df0, piv], sort=False)            \n",
    "            elif api_name == 'api_carrosserie_uitvoering_nummerieke_code':\n",
    "                piv = res.pivot(columns='carrosserie_uitvoering_numeriek_volgnummer')\n",
    "                one_level = [\n",
    "                            re.sub('^api_','', re.sub('_eeg_uitvoering$','',api_name)) + '_' + '_'.join(\n",
    "                                [str(c) if type(c)==int else c for c in l]\n",
    "                            ) for l in piv.columns\n",
    "                        ]\n",
    "                piv.columns = one_level\n",
    "                df0 = pd.concat([df0, piv], sort=False)            \n",
    "            elif api_name == 'api_uitvoeringverbruik_per_uitgave':\n",
    "                piv = res.pivot(columns='uitvgavenummer_verbruikboek')\n",
    "                one_level = [\n",
    "                            re.sub('^api_','', re.sub('_eeg_uitvoering$','',api_name)) + '_' + '_'.join(\n",
    "                                [str(c) if type(c)==int else c for c in l]\n",
    "                            ) for l in piv.columns\n",
    "                        ]\n",
    "                piv.columns = one_level\n",
    "                df0 = pd.concat([df0, piv], sort=False)\n",
    "            elif api_name == 'api_motor_uitvoering':\n",
    "                piv = res.pivot(columns='volgnummer')\n",
    "                one_level = [\n",
    "                            re.sub('^api_','', re.sub('_eeg_uitvoering$','',api_name)) + '_' + '_'.join(\n",
    "                                [str(c) if type(c)==int else c for c in l]\n",
    "                            ) for l in piv.columns\n",
    "                        ]\n",
    "                piv.columns = one_level\n",
    "                df0 = pd.concat([df0, piv], sort=False)\n",
    "            elif api_name == 'api_versnellingsbak_uitvoering':\n",
    "                piv = res.pivot(columns='volgnummer')\n",
    "                one_level = [\n",
    "                            re.sub('^api_','', re.sub('_eeg_uitvoering$','',api_name)) + '_' + '_'.join(\n",
    "                                [str(c) if type(c)==int else c for c in l]\n",
    "                            ) for l in piv.columns\n",
    "                        ]\n",
    "                piv.columns = one_level\n",
    "                df0 = pd.concat([df0, piv], sort=False)\n",
    "            elif api_name == 'api_motor_uitvoering_brandstof':\n",
    "                piv = pd.pivot_table(res, index=res.index.names, columns=['volgnummer', 'brandstof_volgnummer'])\n",
    "                one_level = [\n",
    "                            re.sub('^api_','', re.sub('_eeg_uitvoering$','',api_name)) + '_' + '_'.join(\n",
    "                                [str(c) if type(c)==int else c for c in l]\n",
    "                            ) for l in piv.columns\n",
    "                        ]\n",
    "                piv.columns = one_level\n",
    "                df0 = pd.concat([df0, piv], sort=False)                \n",
    "            elif api_name == 'api_merk_uitvoering_toegestaan':\n",
    "                piv = pd.pivot_table(res, index=res.index.names, values=res.columns, aggfunc=list)\n",
    "                df0 = pd.concat([df0, piv], sort=False)\n",
    "            else:\n",
    "                assert res.shape[0] == 1 # Nothing to pivot on\n",
    "                columns = ['{}_{}'.format(re.sub('^api_','', re.sub('_eeg_uitvoering$','',api_name)), c) for c in res.columns] \n",
    "                res.columns = columns\n",
    "                df0 = pd.concat([df0, res], sort=False)\n",
    "                \n",
    "            print('.', end='')\n",
    "        if len(df0)==0:\n",
    "            print('No results for this api')\n",
    "            continue\n",
    "\n",
    "\n",
    "        # add to dict\n",
    "        rdw_per_confcode[key] = df0\n",
    "        display(rdw_per_confcode[key].tail())\n",
    "        print(rdw_per_confcode[key].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1><a href=\"#rdw_top\">^</a></H1><a id='rdw_ovi'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Closed data from rdw (OVI)\n",
    "Optionally get data from rdw website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closed_data(reg, fields = '*'):\n",
    "    web_url = f'https://ovi.rdw.nl/?kenteken={reg}'\n",
    "\n",
    "    import requests\n",
    "    import codecs\n",
    "    from lxml import html, etree\n",
    "    import re\n",
    "    from time import sleep\n",
    "    \n",
    "    def _all_fields(tree):\n",
    "        elements = tree.xpath('//*[@class=\"ui-block-d border ovigrid\"]') + tree.xpath('//*/div[@class=\"ui-block-d ovigrid\"]')\n",
    "        return [el.attrib['id'] for el in elements if 'id' in el.keys()]\n",
    "    \n",
    "    # get page\n",
    "    page = requests.get(web_url)\n",
    "    DecodeType = re.findall('charset=(.*)$', page.headers[\"Content-type\"])[0]\n",
    "    htmlstring = codecs.decode(page.content, DecodeType)\n",
    "    # Convert string to tree object\n",
    "    tree = html.fromstring(htmlstring)\n",
    "\n",
    "    # analyze results\n",
    "    ERROR = len(tree.xpath('//*[@action=\"FoutPagina.aspx?error=ErrorBlocked\"]')) == 1\n",
    "    warn_text = tree.xpath('//*[@class=\"warning\"]/*/text()')\n",
    "    WARNING_NA = (len(warn_text) > 0) and (warn_text[0].startswith('Er zijn geen gegevens gevonden voor het ingevulde kenteken '))\n",
    "\n",
    "    # return result\n",
    "    if ERROR:\n",
    "        print('X', end='')\n",
    "        return False\n",
    "    elif WARNING_NA:\n",
    "        if VERBOSE > 1: print(warn_text[0])\n",
    "        print('x', end='')\n",
    "        return None\n",
    "    else:\n",
    "        if fields == '*':\n",
    "            fields = _all_fields(tree)\n",
    "        out = dict()\n",
    "        for fld in fields:\n",
    "            txt = tree.xpath(f'//*[@id=\"{fld}\"]/text()')\n",
    "            if len(txt) != 1:\n",
    "                # No result with this field. Just skip\n",
    "                if VERBOSE > 1: print(fld)\n",
    "                print('-', end='')\n",
    "            else:\n",
    "                print('.', end='')\n",
    "                out[fld] = str(txt[0])\n",
    "        # No result with these fields. Probably limit request\n",
    "        if all([v is None for v in out.values()]):\n",
    "            raise AssertionError(f'No result with fields: {\", \".join(fields)}.')\n",
    "\n",
    "\n",
    "    return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbconvert_instruction:remove_all_outputs"
    ]
   },
   "outputs": [],
   "source": [
    "if CLOSEDDATA:\n",
    "    data = {k: False for k in df_regs.kenteken}\n",
    "    if VERBOSE > 1: print('X: error\\n.: info retrieved\\n-: N.A.')\n",
    "    DO_LOOP = True\n",
    "    c = 0 #counter\n",
    "    max_loop = 2 * len(data) / 30 # approx nr of succesful retrievals is 30\n",
    "    while DO_LOOP or c > max_loop:\n",
    "        # pause\n",
    "        if c > 0:\n",
    "            if VERBOSE > 1: print(f' time out (60s) for next iteration', end='')\n",
    "            sleep(60)\n",
    "            if VERBOSE > 1: print(f': {c:2.0f}/{max_loop:2.0f}')\n",
    "        c+=1 \n",
    "\n",
    "        # has no value or field has no value\n",
    "        to_do_regs = [k for k,v in data.items() if v == False]\n",
    "        if VERBOSE > 0: print(f'\\nto do:{len(to_do_regs):3.0f}', end=' ')\n",
    "        data.update({reg: get_closed_data(reg, closed_data_fields) for reg in to_do_regs})\n",
    "        DO_LOOP = any([v==False for v in data.values()])\n",
    "\n",
    "    # drop None\n",
    "    data = {k:v for k,v in data.items() if v is not None}    \n",
    "    rdw_closed = pd.DataFrame.from_dict(data=data, orient='index')\n",
    "else:\n",
    "    rdw_closed = None\n",
    "\n",
    "rdw_closed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1><a href=\"#rdw_top\">^</a></H1><a id='rdw_merge'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge datasets\n",
    "- Merge dataframes from conformity codes apis\n",
    "- Merge with registration results\n",
    "- Merge with auction results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbconvert_instruction:remove_all_outputs"
    ]
   },
   "outputs": [],
   "source": [
    "# first merge first two results\n",
    "tmp = rdw_per_confcode['conformity_codes'].merge(rdw_per_confcode['eeg_voertuigtypegoedkeuring'], how='left', \n",
    "                                              left_on='typegoedkeuringsnummer',\n",
    "                                              right_index=True\n",
    "                                             )\n",
    "\n",
    "tmp.rename(columns={\n",
    "    'eu_type_goedkeuringssleutel_x': 'eu_type_goedkeuringssleutel',\n",
    "    'uitvoering': 'eeg_uitvoeringscode',\n",
    "    'variant': 'eeg_variantcode',\n",
    "    'volgnummer_wijziging_eu_typegoedkeuring': 'uitvoering_wijzigingsnummer',\n",
    "}, inplace=True)\n",
    "tmp.set_index(['eu_type_goedkeuringssleutel', 'eeg_uitvoeringscode', 'eeg_variantcode', 'uitvoering_wijzigingsnummer'], inplace=True)\n",
    "\n",
    "# merge with subsequent api results\n",
    "df_confcodes = pd.concat([tmp] + list(rdw_per_confcode.values())[2:], axis='columns', sort=False)\n",
    "# add timestamp\n",
    "df_confcodes['TimeStamp'] = pd.to_datetime('now').strftime('%Y%m%d')\n",
    "\n",
    "display(df_confcodes.tail())\n",
    "print(df_confcodes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbconvert_instruction:remove_all_outputs"
    ]
   },
   "outputs": [],
   "source": [
    "# Merge confirmation codes with registrations\n",
    "df_regs.index.name = 'lot_index'\n",
    "df = df_regs.reset_index().merge(df_confcodes.reset_index(), how='left',\n",
    "                   left_on=['typegoedkeuringsnummer', 'uitvoering', 'variant', 'volgnummer_wijziging_eu_typegoedkeuring'],\n",
    "                   right_on=['typegoedkeuringsnummer', 'eeg_uitvoeringscode', 'eeg_variantcode', 'uitvoering_wijzigingsnummer'],\n",
    ").set_index('lot_index')\n",
    "display(df.tail(10))\n",
    "print(df.shape)\n",
    "assert all(df.columns.value_counts() == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge closed source data with registrations\n",
    "\n",
    "# make fields lowercase and add \"ovi_\"\n",
    "rdw_closed.index.name='kenteken'\n",
    "rdw_closed.columns = ['ovi' + re.sub(r'([A-Z])',r'_\\1', c).lower() for c in rdw_closed.columns]\n",
    "\n",
    "# Basic operations\n",
    "rdw_closed['ovi_private_owners'] = rdw_closed.ovi_eigenaren.str.split('/').apply(lambda x:int(x[0].strip()))\n",
    "rdw_closed['ovi_company_owner'] = rdw_closed.ovi_eigenaren.str.split('/').apply(lambda x:int(x[1].strip()))\n",
    "rdw_closed['ovi_owners'] = rdw_closed['ovi_private_owners'] + rdw_closed['ovi_company_owner']\n",
    "rdw_closed['ovi_under_survey'] = rdw_closed.ovi_wachten_op_keuring.apply(lambda x: {'Ja': True, 'Nee': False}[x])\n",
    "\n",
    "df = df.merge(rdw_closed, how='left', left_on='kenteken', right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge rdw and drz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge auction results and rdw queries. Add prefix \"rdw_\"\n",
    "rdw = pd.concat([drz, df.add_prefix('rdw_')], axis='columns', sort=False)\n",
    "# There should be no duplicates in column names\n",
    "assert all(rdw.columns.value_counts() == 1)\n",
    "# indices should match\n",
    "assert rdw.index.isin(drz.index).all() & drz.index.isin(rdw.index).all()\n",
    "\n",
    "out = rdw.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbconvert_instruction:remove_all_outputs"
    ]
   },
   "outputs": [],
   "source": [
    "if OPBOD:\n",
    "    file_name = f'../../../python-nb/data/rdw-data-opbod-{DATE}.pkl'\n",
    "else:\n",
    "    file_name = f'../data/rdw-data-{DATE}.pkl'\n",
    "\n",
    "if NO_PRICE:\n",
    "    file_name = file_name.replace('.pkl', '-without-price.pkl')\n",
    "    \n",
    "if (SKIPSAVE==False) and (not(os.path.isfile(file_name))):\n",
    "    print(file_name)\n",
    "    out.to_pickle(file_name)\n",
    "else:\n",
    "    print(f'Skip. {file_name} exists or saving is disabled in settings.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next: download images (or parallel)\n",
    "\n",
    "Because images might be taken down from the drz site, it is advisable to run the notebook that downloads images soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Stop running. check if existing file has same dataframe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-206-22141f7bd216>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Stop running. check if existing file has same dataframe'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: Stop running. check if existing file has same dataframe"
     ]
    }
   ],
   "source": [
    "assert False, 'Stop running. Below is to check if existing file has same dataframe.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdw = pd.read_pickle('../data/rdw-data-2021-06-opzij.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_eq = rdw.eq(out)\n",
    "is_na = rdw.isna() & out.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'Raw_text'\n",
    "\n",
    "c = 0\n",
    "for aa,bb in zip(rdw[col],out[col]):\n",
    "    c+=1\n",
    "    sd1 = np.setdiff1d(aa,bb)\n",
    "    sd2 = np.setdiff1d(bb,aa)\n",
    "    if (len(sd1) == 1 & len(sd2) == 1) & (sd2[0][:-1] == sd1[0]):\n",
    "        continue\n",
    "    else:\n",
    "        if sd1:\n",
    "            for l in sd1:\n",
    "                print(f'|{l}|')\n",
    "        if sd2:\n",
    "            for l in sd2:\n",
    "                print(f'|{l}|')\n",
    "        raise\n",
    "            \n",
    "is_eq[col] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'LotCat'\n",
    "\n",
    "c = 0\n",
    "for aa,bb in zip(rdw[col],out[col]):\n",
    "    c+=1\n",
    "    sd1 = np.setdiff1d(aa,bb)\n",
    "    sd2 = np.setdiff1d(bb,aa)\n",
    "    if (len(sd1) == 1 & len(sd2) == 1) & (sd2[0][:-1] == sd1[0]):\n",
    "        continue\n",
    "    else:\n",
    "        if sd1:\n",
    "            for l in sd1:\n",
    "                print(f'|{l}|')\n",
    "        if sd2:\n",
    "            for l in sd2:\n",
    "                print(f'|{l}|')\n",
    "        raise\n",
    "            \n",
    "is_eq[col] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = (is_na | is_eq)\n",
    "\n",
    "sel.loc[:, sel.columns.str.startswith('rdw_TimeStamp')] = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([\n",
    "    pd.concat([rdw.loc[(sel == False).any(axis=1), sel.all() == False]], keys=['on disk'], axis=1),\n",
    "    pd.concat([out.loc[(sel == False).any(axis=1), sel.all() == False]], keys=['memory'], axis=1)\n",
    "], axis = 1).sort_index(level=1, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in rdw.loc[:, sel.all() == False].columns:\n",
    "    print(col)\n",
    "    display(pd.concat([\n",
    "        rdw.loc[sel[col]==False, col], \n",
    "        out.loc[sel[col]==False, col]\n",
    "    ], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
