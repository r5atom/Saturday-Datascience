{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZUVC3jZAoqW8"
   },
   "source": [
    "# Store results of auction of Dienst Roerende Zaken\n",
    "Monthy results of auction are publicized on http://www.domeinenrz.nl/catalogus. This Notebook scrapes the result from the drz website and parses the text and stores it in a dataframe.  \n",
    "- - - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gX4yHh2yoqW9"
   },
   "source": [
    "### User variables\n",
    "- `Date`: Date of current results. This is needed to create proper url  \n",
    "- `Verbose`: Debug variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xQEkKUsFoqW_"
   },
   "outputs": [],
   "source": [
    "Date = '2019-07' # yyyy-mm\n",
    "Verbose = 0 # debug level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7cxUAb4ooqXF"
   },
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bx1a6Z1roqXH"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib\n",
    "from lxml import html, etree\n",
    "import requests\n",
    "import codecs \n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'maandag 01 juli'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# needed for new (as of feb '18) url format\n",
    "import locale\n",
    "locale.setlocale(locale.LC_TIME,'nl_NL')\n",
    "pd.to_datetime('now').strftime('%A %d %B')\n",
    "pd.to_datetime(Date,format='%Y-%m').strftime('%A %d %B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4sU80MNcoqXM"
   },
   "source": [
    "### Internal variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sbrj-23roqXO"
   },
   "outputs": [],
   "source": [
    "# website with results\n",
    "url = 'http://www.domeinenrz.nl/catalogus'\n",
    "\n",
    "# IRS (belastingdienst) auction was added. Naming of url changed.\n",
    "if pd.to_datetime(Date,format='%Y-%m') >= pd.to_datetime('2019-05',format='%Y-%m'):\n",
    "    url = 'http://www.domeinenrz.nl/catalogi'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4e7IXDC3oqXS"
   },
   "source": [
    "### Read external data\n",
    "These files are used to recognize text fragments. Regex patterns are mapped to field names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O2TBeyJooqXU"
   },
   "outputs": [],
   "source": [
    "tags=pd.read_csv('./regex-patterns/drz-re-patt-tag.txt',\n",
    "                    comment='#',\n",
    "                    header=None,\n",
    "                    quotechar='\"',\n",
    "                    delimiter=\",\",\n",
    "                    skipinitialspace=True).rename(columns={0 : 'Field',1 : 'Pattern'})\n",
    "                    \n",
    "flagtags=pd.read_csv('./regex-patterns/drz-re-patt-hastag.txt',\n",
    "                     comment='#',\n",
    "                     header=None,\n",
    "                     quotechar='\"',\n",
    "                     delimiter=\",\",\n",
    "                     skipinitialspace=True).rename(columns={0 : 'Field',1 : 'Pattern'})\n",
    "\n",
    "repfragments=pd.read_csv('./regex-patterns/drz-re-patt-replace.txt',\n",
    "                      comment='#',\n",
    "                      header=None,\n",
    "                      quotechar='\"',\n",
    "                      delimiter=\",\",\n",
    "                      skipinitialspace=True).rename(columns={0 : 'Pattern',1 : 'Replace'}).fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y-Gt2XG9oqXY"
   },
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TakJjiuyoqXZ"
   },
   "outputs": [],
   "source": [
    "def gettree(baseurl,Lotid,Date=Date,disp=False):\n",
    "    \n",
    "    '''\n",
    "    tree from url. Version where urls are formatted as \n",
    "    http://www.domeinenrz.nl/catalogus/verkoop_bij_inschrijving_2018-0009?=&meerfotos=K1800091800\"\n",
    "    later it even changed to:\n",
    "    .  .  .  .  .  .  . klik_hier_voor_verkoop_bij_inschrijving_2018-0011\n",
    "    '''\n",
    "    \n",
    "    # Change date format and extend to url\n",
    "    Datestr = Date.replace('-','-00')\n",
    "    if pd.to_datetime(Datestr,format='%Y-00%m') < pd.to_datetime('2018-0011',format='%Y-00%m'):\n",
    "        baseurl += '/verkoop_bij_inschrijving_{:s}'.format(Datestr)\n",
    "    elif pd.to_datetime(Datestr,format='%Y-00%m') < pd.to_datetime('2019-0002',format='%Y-00%m'):\n",
    "        baseurl += '/klik_hier_voor_verkoop_bij_inschrijving_{:s}'.format(Datestr)\n",
    "    elif pd.to_datetime(Datestr,format='%Y-00%m') < pd.to_datetime('2019-0005',format='%Y-00%m'):\n",
    "        baseurl += '/verkoop_bij_inschrijving_{:s}_{:s}'.format(Datestr,pd.to_datetime(Datestr,format='%Y-00%m').strftime('%B'))\n",
    "    else:\n",
    "        baseurl += '/verkoop_bij_inschrijving_{:s}'.format(Datestr)\n",
    "        \n",
    "    # create url\n",
    "    urldata = {}\n",
    "    urldata[''] = '' # to create '=&'. This might be a bug in the site \n",
    "    \n",
    "    # Add auction id\n",
    "    urldata['veilingen'] = Datestr\n",
    "\n",
    "    # Add lot number\n",
    "    urldata['meerfotos'] = Lotid\n",
    "    # generate url with urldata\n",
    "    KavelUrl = baseurl + '?' + urllib.parse.urlencode(urldata)\n",
    "    if disp: print(KavelUrl)\n",
    "    \n",
    "    # get html string\n",
    "    req_success = False\n",
    "    c=0\n",
    "    while req_success == False:\n",
    "        c+=1\n",
    "        try:\n",
    "            page = requests.get(KavelUrl)\n",
    "            req_success = True\n",
    "        except:\n",
    "            if c > 10:\n",
    "                raise Exception('Retried, but failed')\n",
    "            else:\n",
    "                print('pause 1 sec and try again!')\n",
    "                time.sleep(1)\n",
    "                req_success = False\n",
    "\n",
    "    # find encoding\n",
    "    DecodeType = page.headers[\"Content-type\"]\n",
    "    T = 'charset='\n",
    "    DecodeType = DecodeType[DecodeType.find(T)+len(T):]\n",
    "    # convert to unicode\n",
    "    htmlstring = codecs.decode(page.content, DecodeType)\n",
    "    # convert string to tree object\n",
    "    tree = html.fromstring(htmlstring)\n",
    "    \n",
    "    return tree,KavelUrl\n",
    "\n",
    "def gettree_v1(baseurl,Lot,Date=None,disp=False):\n",
    "    \n",
    "    '''\n",
    "    tree from url. Version where urls are formatted as \n",
    "    http://www.domeinenrz.nl/catalogus?=&meerfotos=1799&veilingen=2018-09\"\n",
    "    '''\n",
    "    \n",
    "    # create url\n",
    "    urldata = {}\n",
    "    urldata[''] = '' # to create '=&'. This might be a bug in the site \n",
    "    # was date in input?\n",
    "    if Date != None and len(Date) != 0:\n",
    "        urldata['veilingen'] = Date\n",
    "    # Add lot number\n",
    "    urldata['meerfotos'] = Lot\n",
    "    # generate url with urldata\n",
    "    KavelUrl = baseurl + '?' + urllib.parse.urlencode(urldata)\n",
    "    if disp: print(KavelUrl)\n",
    "    \n",
    "    # get html string\n",
    "    page = requests.get(KavelUrl)\n",
    "    # find encoding\n",
    "    DecodeType = page.headers[\"Content-type\"]\n",
    "    T = 'charset='\n",
    "    DecodeType = DecodeType[DecodeType.find(T)+len(T):]\n",
    "    # convert to unicode\n",
    "    htmlstring = codecs.decode(page.content, DecodeType)\n",
    "    # convert string to tree object\n",
    "    tree = html.fromstring(htmlstring)\n",
    "    \n",
    "    return tree,KavelUrl\n",
    "\n",
    "\n",
    "def extractitem(tree,name,disp=False):\n",
    "    \"extract lines from tree\"\n",
    "    \n",
    "    if name == \"title\":\n",
    "        \n",
    "        '''\n",
    "        Return title of this page. This can be found in a H4 with class name 'title'.\n",
    "        '''\n",
    "            \n",
    "        # path = '//body/div[@id=\"mainwrapper\"]/div[@id=\"main\"]/div[@class=\"wrapper\"]/div[@class=\"article\"]/div[@class=\"catalogus\"]/div[@class=\"catalogusdetailitem split-item-first\"]/a/h4[@class=\"title\"]//text()'\n",
    "        path = '//h4[@class=\"title\"]/text()'\n",
    "        return tree.xpath(path)[0].strip()\n",
    "\n",
    "    elif name == \"images\":\n",
    "        \n",
    "        '''\n",
    "        Return urls (src) of images. These are inside divs of class 'photo'\n",
    "        '''\n",
    "        \n",
    "        lines = [item.get('src') for item in tree.xpath('//div[@class=\"photo\"]/img')]\n",
    "        \n",
    "        if disp:\n",
    "            print(lines)\n",
    "        \n",
    "        return lines\n",
    "    \n",
    "    elif name == \"text\":\n",
    "        \n",
    "        '''\n",
    "        Just return all relevant text, which is in class 'catalogusdetailitem split-item-first'.\n",
    "        '''\n",
    "        \n",
    "        lines=tree.xpath('//div[@class=\"catalogusdetailitem split-item-first\"]/text()')\n",
    "        \n",
    "        if disp:\n",
    "            print(len(lines))\n",
    "        \n",
    "        return lines\n",
    "    \n",
    "    elif name == \"date\":\n",
    "        \n",
    "        '''\n",
    "        Return date of this auction by taking the title of the page.\n",
    "        This is pretty obsolete, because date is given at start of this notebook.\n",
    "        '''\n",
    "        \n",
    "        lines = tree.xpath('//title/text()')\n",
    "        Date = lines[0]\n",
    "        \n",
    "        if 'Verkoop catalogus ' in Date:\n",
    "            # title like \"Verkoop catalogus 2017-12\"\n",
    "            Date = re.match('Verkoop catalogus (.*)',Date)[1]\n",
    "\n",
    "        elif 'Verkoop bij inschrijving ' in Date:\n",
    "            # title like \"Verkoop bij inschrijving 2019-0001 januari\"\n",
    "            M = re.match('Verkoop bij inschrijving (20[0-9]{2})-00([0-9]{2}).*',Date)\n",
    "            print(M.group(2))\n",
    "            Date = '-'.join([M.group(1),M.group(2)])\n",
    "\n",
    "        else:\n",
    "            raise Exception('TODO: implement')\n",
    "\n",
    "        # Date = Date.strip()\n",
    "        # T = 'Verkoop catalogus '\n",
    "        # Date = Date[Date.index(T)+len(T):]\n",
    "        \n",
    "        return Date\n",
    "    \n",
    "    elif name == \"nextlot\":\n",
    "        \n",
    "        '''\n",
    "        Return number of next lot by checking out the link to the next lot in the current page.\n",
    "        'K1900011801' will become 1801\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        # link to next lot\n",
    "        Link = tree.xpath('//div[@class=\"catalogusdetailitem split-item-first\"]/div[4]/div[3]/a')\n",
    "        Tar = Link[0].get(\"href\")\n",
    "        \n",
    "        # extract lot name\n",
    "        #nextLot = re.match('\\?meerfotos=(.*)',Tar).group(1)\n",
    "        nextLot = re.match('.*[\\?,\\&]meerfotos=(.*)(\\&.*)?',Tar).group(1)\n",
    "\n",
    "        if \"&veilingen=\" in nextLot:\n",
    "            nextLot = re.match('(.*)&',nextLot).group(1)\n",
    "            \n",
    "        # convert to integer\n",
    "        nextLot = int(nextLot[-4:])\n",
    "\n",
    "        if disp:\n",
    "            print(nextLot,Tar,etree.tostring(Link[0]))\n",
    "                \n",
    "        return nextLot\n",
    "    \n",
    "    elif name == \"price\":\n",
    "        \n",
    "        '''\n",
    "        Return price as float\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        # price can be bold or strong\n",
    "        Price = tree.xpath('//div[@class=\"catalogusdetailitem split-item-first\"]/strong/text()')\n",
    "        if len(Price) == 0:\n",
    "            Price = tree.xpath('//b/text()')\n",
    "\n",
    "        if disp: print(Price)\n",
    "        \n",
    "        if len(Price) == 0:\n",
    "            print('No Price found! use 0 for now')\n",
    "            print(*tree.xpath('//*[@class=\"catalogusdetailitem split-item-first\"]/text()'))\n",
    "            Price = ['Niet gegund']\n",
    "            raise Exception('Fix this')\n",
    "        \n",
    "        # select first in list (xpath returns lists)\n",
    "        Price = Price[0]\n",
    "            \n",
    "        if Price == 'Na loting':\n",
    "            Price = tree.xpath('//strong/text()')[0]\n",
    "            Draw = True\n",
    "        else:\n",
    "            Draw = False        \n",
    " \n",
    "        Tags = ['Zie kavel','Zie massakavel']# part of combination lot\n",
    "        if any([Tag in Price for Tag in Tags]) :\n",
    "            Price = 0\n",
    "        elif Price == 'Niet gegund':\n",
    "            Price = 0\n",
    "        else:\n",
    "            M = re.match(u'Gegund voor: \\u20ac *([0-9,.]*,[0-9]{2}) *\\(excl. alle eventuele bijkomende kosten en belastingen\\)',Price)\n",
    "            if disp:print(M.group(0))\n",
    "            Price = float(M.group(1).replace('.','').replace(',','.'))\n",
    "            # Tag1 = u'Gegund voor: \\u20ac'\n",
    "            # Tag2 = u'(excl. alle eventuele bijkomende kosten en belastingen)'\n",
    "            # Price = float(Price[Price.index(Tag1)+len(Tag1):Price.index(Tag2)].strip().replace('.','').replace(',','.'))\n",
    "            \n",
    "        return Price,Draw\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4UnVXeYSoqXd"
   },
   "source": [
    "### First: Get all results from all pages\n",
    "This will read all pages and the raw text is stored for later use.  \n",
    "The \"**next lot**\" is linked in the current result. The function will look for this link and proceed. Because it is not know what the first lot will be, it is hard coded at `Lot = 1799`. It will increment with a step of `+1` to find the first lot. If the first lot is not (yet) found a period (`.`) is printed, otherwise the lot nummer will be printed. The console output should start with \"`.`\" (a period).  \n",
    "Searching for next lots will continue untill the next lot has a **smaller** value that the current. This will cause the routine to stop when the last lot points back to the first lot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PZlJTn_eoqXf",
    "outputId": "452f8b6c-e71d-4b26-df5b-10b4d97c3aa2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".-.-1801>1802>1804>1805>1806>1808>1809>1810>1811>1812>1813>1814>1815>1816>1817>1818>1819>1820>1821>1822>1823>1825>1826>1827>1828>1830>1831>1832>1834>1848>1849>1850>1852>1853>1854>1855>1856>2200>2201>2202>2203>2204>2205>2206>2208>2209>2210>2211>2212>2213>2214>2215>2217>2218>2219>2220>2221>2222>2400>2401>2402>2403>2404>2405>2406>2408>2409>2410>2411>2600>2601>2602>2603>2604>2605>2607>2609>2610>2611>2612>2613>2614>7100>7101>7102>7103>7104>7105>7106>7107>7108>7109>7110>7111>7112>7113>7115>7116>7117>7119>7120>7121>7122>7123>7124>7125>7126>7127>7128>7130>7131>7132>7133>7134>7136>7138>7140>7142>7143>7144>7145>7146>7147>7150>7152>7153>7154>7155>7156>7157>7158>7159>7160>7163>7164>7165>7166>7167>7168>7169>7170>7171>7172>7173>7174>7175>7176>7178>7179>7180>7181>7182>7183>7184>7185>7186>7187>7188>7189>7190>7191>7192>7193>7194>7195>7196>7197>7199>7200>7201>7202>7203>7204>7205>7207>7208>7211>7212>7213>7215>7216>7218>7219>7220>7221>7222>7223>7224>7225>7227>7228>7231>7232>7233>7234>7235>7237>7240>7241>7242>7243>7244>7246>7247>7248>7250>7251>7252>7253>7254>9600>9700>9800>.X"
     ]
    }
   ],
   "source": [
    "# empty lists\n",
    "AllLot = []\n",
    "AllTree = []\n",
    "AllKavelUrl = []\n",
    "doLoop = True # set to false at the end.\n",
    "Lot = 1799 # first\n",
    "while doLoop:\n",
    "    # Lot id\n",
    "    # 'K1800091800'\n",
    "    Lotid = 'K{:s}00{:s}{:.0f}'.format(Date[2:4],Date[5:8],Lot)\n",
    "    \n",
    "    # read page\n",
    "    read_success = False\n",
    "    c=0\n",
    "    while read_success == False:\n",
    "        c+=1\n",
    "        if pd.to_datetime(Date, format = '%Y-%m') < pd.to_datetime('2018-9-1'):\n",
    "            [Tree,KavelUrl]=gettree_v1(url,Lot=str(Lot),Date=Date,disp=Verbose>1)\n",
    "        else:\n",
    "            [Tree,KavelUrl]=gettree(url,Lotid=Lotid,Date=Date,disp=Verbose>1)\n",
    "        Content = Tree.xpath('//*[@id=\"content\"]/div[1]/b/text()')\n",
    "        if Content == 'failed': # future\n",
    "            if c > 10:\n",
    "                raise Exception('Retried, but failed')\n",
    "            else:\n",
    "                print('pause 1 sec and try again!')\n",
    "                time.sleep(1)\n",
    "                read_success = False\n",
    "        else:\n",
    "            read_success = True\n",
    "    \n",
    "    if Content and Content[0] == 'Niets gevonden.':\n",
    "        # Lot number does not exist\n",
    "        NextLot = Lot + 1\n",
    "        print('.',end='-')\n",
    "    else :\n",
    "        # find next number\n",
    "        try:\n",
    "            NextLot=extractitem(Tree,'nextlot')\n",
    "        except:\n",
    "            print(KavelUrl)\n",
    "            print('try again',end='>')\n",
    "            NextLot = Lot\n",
    "#             continue\n",
    "#             print (etree.tostring(Tree,pretty_print=True).decode('utf8'))\n",
    "            raise \n",
    "                   \n",
    "        # add current results to list\n",
    "        AllLot.append(Lot)\n",
    "        AllTree.append(Tree)\n",
    "        AllKavelUrl.append(KavelUrl)\n",
    "        print(str(Lot),end='>')\n",
    "    if NextLot < Lot :\n",
    "        # First Lot again. Break loop\n",
    "        doLoop = False\n",
    "    else :\n",
    "        Lot = NextLot\n",
    "\n",
    "print('.',end='X')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jgD8U0EGoqXm"
   },
   "source": [
    "### Basic parsing\n",
    "Raw text is parsed for the first time. Some basics are stored in a pandas.DataFrame:  \n",
    "- price\n",
    "- image urls\n",
    "- title\n",
    "- .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XBxEI6ipoqXn"
   },
   "outputs": [],
   "source": [
    "Verbose = 0\n",
    "# empty list\n",
    "out = None\n",
    "# loop over all pages\n",
    "for iK, tree in enumerate(AllTree):\n",
    "    \n",
    "    #\n",
    "    # create an index\n",
    "    #\n",
    "\n",
    "    #   date\n",
    "    if \"Date\" not in locals() or not Date:\n",
    "        Date = extractitem(tree,'date',disp=Verbose>2)\n",
    "\n",
    "    DT = pd.to_datetime(Date,format=\"%Y-%m\")\n",
    "    \n",
    "    #   title and lot number\n",
    "    title = extractitem(tree,'title')\n",
    "    Lotid = re.match('Kavel (.*)',title).group(1)\n",
    "    #Lotid = title[len('Kavel '):]\n",
    "    if Lotid.startswith('K'):\n",
    "        Lot = int(Lotid[-4:])\n",
    "    else:\n",
    "        Lot = int(Lotid)\n",
    "\n",
    "    #   index\n",
    "    IX = \"-\".join([str(DT.year),str(DT.month),str(Lot)])\n",
    "\n",
    "    if Verbose>0: print(IX)\n",
    "    \n",
    "    \n",
    "    #\n",
    "    # extract images\n",
    "    #\n",
    "    \n",
    "    \n",
    "    image_urls = [re.sub('\\/catalog((us)|(i))','',url) + item for item in extractitem(tree,'images',disp=Verbose>2)]\n",
    "    \n",
    "    #if Verbose>0: print(image_urls)\n",
    "            \n",
    "     \n",
    "    #\n",
    "    # Price\n",
    "    #\n",
    "    \n",
    "    [Price,Draw] = extractitem(tree,'price',disp=Verbose>2)\n",
    "        \n",
    "        \n",
    "        \n",
    "    #    \n",
    "    # add to data frame\n",
    "    #\n",
    "    \n",
    "    out = pd.concat([out,pd.DataFrame({'Source' : AllKavelUrl[iK],\n",
    "                                      'Title' : title,\n",
    "                                      'Price' : Price,\n",
    "                                      'Draw' : Draw,\n",
    "                                      'Raw_text' : [extractitem(tree,'text')],\n",
    "                                      'N_images' : len(image_urls),\n",
    "                                      'Images' : [image_urls]},\n",
    "                                      index = [IX])])\n",
    "out.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zjWGHXv2oqXy"
   },
   "source": [
    "### In depth parsing\n",
    "Do some more sofisticated parsing. Use `Raw_text` as input.  \n",
    "When a line is not recognized. It will be printed to console. One might choose to add to the external text files if a fragment of tag occurs often."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L1Ux7kpGoqXz",
    "outputId": "52a96be4-15c7-498f-af8b-9a8c4d537e59"
   },
   "outputs": [],
   "source": [
    "Verbose = 0\n",
    "# parse raw text\n",
    "for IX in out.index :\n",
    "    \n",
    "    # find info\n",
    "    \n",
    "    rt = out.loc[IX,\"Raw_text\"]\n",
    "    \n",
    "    # first line:\n",
    "    \n",
    "    # Is it a draw?\n",
    "    Val = rt.pop(0) \n",
    "    if Val == 'Na loting':\n",
    "        Val = rt.pop(0) # val is now kavelnr\n",
    "        out.loc[IX,\"Draw\"] = True\n",
    "    else:\n",
    "        out.loc[IX,\"Draw\"] = False\n",
    "    \n",
    "    # when lot number is followed by an asteriks there is a note\n",
    "    if Val.endswith('*\\r'):\n",
    "        Val = Val[0:-2]\n",
    "        out.loc[IX,\"Note\"] = True\n",
    "    else :\n",
    "        Val = Val.strip()\n",
    "        out.loc[IX,'Note'] = False\n",
    "        \n",
    "    if Verbose>0:\n",
    "        print(Val)\n",
    "\n",
    "    # store lot nr        \n",
    "    out.loc[IX,\"LotNr\"]=Val\n",
    "    \n",
    "    \n",
    "    # second line\n",
    "    out.loc[IX,\"LotType\"]=rt.pop(0).strip()\n",
    "\n",
    "    # third line\n",
    "    Val = rt.pop(0).strip()\n",
    "    # This line is brand or optional line with type of lot\n",
    "    # All caps is brand\n",
    "    if Val in ['Quad','Kampeerwagen/ camper','Pleziervaart motorvaartuig met opbouw en open kuip','Rubberboot'] or not Val.isupper():\n",
    "        out.loc[IX,\"LotType\"] += ''.join([' (' + Val + ')'])\n",
    "        if Verbose>0:print(Val)\n",
    "        Val = rt.pop(0).strip() # now it is brand\n",
    "    out.loc[IX,\"ItemBrand\"]=Val\n",
    "\n",
    "    \n",
    "    \n",
    "    # escape characters, repair typos and translate \n",
    "    for i in range(len(rt)):\n",
    "        \n",
    "        # encode string as bytes\n",
    "        rt[i] = rt[i].encode('ascii',errors='xmlcharrefreplace')\n",
    "        \n",
    "        # replace text\n",
    "        for pat,sub in zip(repfragments.Pattern,repfragments.Replace):\n",
    "            rt[i] = re.sub(pat.encode('ascii',errors='xmlcharrefreplace'),sub.encode('ascii',errors='xmlcharrefreplace'),rt[i])\n",
    "        \n",
    "        # decode back to string, but special characters escaped to xml\n",
    "        rt[i]=rt[i].decode('ascii')\n",
    "\n",
    "    # Pull value after trailing or leading pattern (bgntag/endtag)\n",
    "    for Tag,Field in zip(tags.Pattern,tags.Field):\n",
    "        M = re.search(Tag,'\\n'.join(rt))\n",
    "        if M:\n",
    "            Val = M.group('val')\n",
    "            if Verbose>2:\n",
    "                print(str(Field) + ' : ' + M.group(0).replace('\\n','[newline]') + '\\n\\t' + '|' + Val + '|')\n",
    "            # remove pattern and make rt a list again.\n",
    "            rt = '\\n'.join(rt).replace(M.group(0),'').split('\\n')\n",
    "        else:\n",
    "            Val = ''\n",
    "        out.loc[IX,Field] = Val        \n",
    "\n",
    "    # Pattern in full text? (flagtag)\n",
    "    for Tag,Field in zip(flagtags.Pattern,flagtags.Field):\n",
    "        # flagtags might occur more than once, hence a list of finditer results\n",
    "        Ms = list(re.finditer(Tag,'\\n'.join(rt)))\n",
    "        if Ms:\n",
    "            Val = True\n",
    "            for M in Ms:\n",
    "                if Verbose>2:\n",
    "                    print(str(Field) + ' : ' + M.group(0).replace('\\n','[newline]') + '\\n\\t' + '|' + str(Val) + '|')\n",
    "                # remove pattern and make rt a list again.\n",
    "                rt = '\\n'.join(rt).replace(M.group(0),'').split('\\n')\n",
    "        else:\n",
    "            Val = False\n",
    "        out.loc[IX,Field] = Val\n",
    "\n",
    "        \n",
    "        \n",
    "    # loop trough remaining lines\n",
    "\n",
    "    for line in rt:\n",
    "               \n",
    "        # do comparison in bytes\n",
    "        line = line.encode('ascii',errors='xmlcharrefreplace')\n",
    "        if Verbose>2:\n",
    "            print(line)\n",
    "            \n",
    "        # parsing\n",
    "        isParsed = False # some accounting: in the end this line should be parsed\n",
    "         \n",
    "        # line is empty.. skip .. next\n",
    "        if not line :# empty\n",
    "            isParsed = True\n",
    "            continue\n",
    "            \n",
    "        # line starting with '*' is a note\n",
    "        if out.loc[IX,'Note'] and line.startswith(bytes('*','ascii')):\n",
    "            if Verbose>2:\n",
    "                print('\\tNote:',end='')\n",
    "                print(out.loc[IX,'Note'],end='')\n",
    "                print(line)\n",
    "            Val = line[1:].decode('ascii')\n",
    "            out.loc[IX,'Note'] = Val\n",
    "            isParsed = True\n",
    "            continue\n",
    "                \n",
    "        if isParsed == False:\n",
    "            line = line.decode('ascii')\n",
    "            \n",
    "            # create empty string if not exist\n",
    "            if (\n",
    "                'SupInfo' not in out.loc[IX].index\n",
    "            ) or (\n",
    "                (\n",
    "                    type(out.loc[IX,'SupInfo']) != str\n",
    "                ) and (\n",
    "                    pd.np.isnan(out.loc[IX,'SupInfo'])\n",
    "                )\n",
    "            ):\n",
    "                out.loc[IX,'SupInfo'] = ''\n",
    "            out.loc[IX,\"SupInfo\"] = '\\n'.join([out.loc[IX,'SupInfo'] , str(line)])\n",
    "            print(str(IX) + '[' + str(line) + ']')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bK_nuHF4oqX4",
    "outputId": "a36b24bc-dc41-40c0-8cf1-a60f8231f7fa"
   },
   "outputs": [],
   "source": [
    "out.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fo02f8-xoqX9"
   },
   "source": [
    "### Save results to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XAjwErGEoqX-",
    "outputId": "b36ddebe-0b99-4a6d-9048-e2bf58f9d705"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/drz-data-2019-07.pkl\n"
     ]
    }
   ],
   "source": [
    "file_name = '../data/drz-data-{}.pkl'.format(Date)\n",
    "print(file_name)\n",
    "out.to_pickle(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LlXxxXRooqYC",
    "outputId": "4a9b9e2c-67f4-454f-ad69-7a4930ad9a91"
   },
   "source": [
    "# Next: add rdw data\n",
    "\n",
    "Because rdw data changes constantly it is advisable to run the notebook that adds rdw data to the above results soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "scrape-drz-auction-result.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
