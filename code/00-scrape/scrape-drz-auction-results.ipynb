{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='auct_top'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape results of auction\n",
    "Monthy results of auction are publicized on https://verkoop.domeinenrz.nl. This Notebook scrapes the result from the drz website and parses the text and stores it in a dataframe.\n",
    "\n",
    "1. <a href=\"#auct_dl_results\">Download results</a>  \n",
    "    This will read all raw text from pages.  \n",
    "2. <a href=\"#auct_basic_parse\">Basic parsing</a>  \n",
    "    Raw text is parsed for the first time. Some basics elements are stored in a pandas.DataFrame (price, image urls, title, ..)\n",
    "3. <a href=\"#auct_regex\">Regex parsing</a>   \n",
    "    Do some more sophisticated parsing by using regular expressions.  \n",
    "4. <a href=\"#auct_save\">Save to disk</a>\n",
    "\n",
    "- - - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbconvert_instruction:remove_all_outputs"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# setting path\n",
    "os.chdir(r'..')\n",
    "\n",
    "import drz_config\n",
    "cfg = drz_config.read_config()\n",
    "DATE = cfg['DATE']\n",
    "VERBOSE = cfg['VERBOSE']\n",
    "OPBOD = cfg['OPBOD']\n",
    "URL = cfg['URL']\n",
    "EXTEND_URL = cfg['EXTEND_URL']\n",
    "SKIPSAVE=cfg['SKIPSAVE']\n",
    "# month_counter = DATE[5:8] # mm\n",
    "if not OPBOD:\n",
    "    month_counter = URL[-2:]\n",
    "else:\n",
    "    month_counter = URL[-4:-2]\n",
    "\n",
    "if VERBOSE > 0:\n",
    "    display(cfg)\n",
    "else:\n",
    "    print(URL)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Virtual environment: py38-satdatsci\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "# needed for as of feb '18 url format\n",
    "import locale\n",
    "try:\n",
    "    locale.setlocale(locale.LC_TIME,'nl_NL')\n",
    "except:\n",
    "    locale.setlocale(locale.LC_TIME,'nl_NL.utf8')\n",
    "\n",
    "# virtualenv\n",
    "M = re.match('\\((.*?)\\) ', os.popen('echo $PS1').read())\n",
    "# os.popen('echo -n $VIRTUAL_ENV').read()\n",
    "if M is not None:\n",
    "    print(f'Virtual environment: {M[1]}')\n",
    "else:\n",
    "    print('Virtual environment not activated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbconvert_instruction:remove_all_outputs"
    ]
   },
   "outputs": [],
   "source": [
    "now = pd.to_datetime('now').strftime('%Y-%m')\n",
    "if now != DATE:\n",
    "    raise ValueError(f'''\n",
    "    Settings file has date set at [{DATE}] but expected [{now}]. Has <{cfg['settings_fn']}> file been updated?\n",
    "    With older auctions it sometimes works to add [url_add_veilingen=True]\n",
    "    ''')\n",
    "    \n",
    "del(now)\n",
    "\n",
    "pd.to_datetime('now').strftime('%A %d %B'), pd.to_datetime(DATE,format='%Y-%m').strftime('%A %d %B')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If auction was in past. Url needs to be extended by setting `add_veilingen = True`:\n",
    "#add_veilingen = True\n",
    "#EXTEND_URL = add_veilingen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbconvert_instruction:remove_all_outputs"
    ]
   },
   "outputs": [],
   "source": [
    "def get_kavel_url(OPBOD, base_url, add_veilingen, lot_id):\n",
    "    \n",
    "    '''\n",
    "    Create url\n",
    "    '''\n",
    "\n",
    "    import urllib\n",
    "    \n",
    "   \n",
    "    # Add field to dicts that are passed to urlencode\n",
    "    urldata = {}\n",
    "    if not OPBOD:\n",
    "        # to create '=&'. This might be a bug in the site \n",
    "        urldata[''] = ''\n",
    "    \n",
    "    # Add auction id\n",
    "    if add_veilingen:\n",
    "        # get date from url\n",
    "        date_string = re.findall(r'_([0-9]{4}-[0-9]{4})', base_url)\n",
    "        urldata['veilingen'] = ''.join(date_string)\n",
    "\n",
    "    # Status is specific for \"opbod\"\n",
    "    if OPBOD:\n",
    "        urldata['status'] = 'both' # or \"closed\"        \n",
    "\n",
    "    # Add lot number\n",
    "    urldata['meerfotos'] = lot_id\n",
    "    \n",
    "    # Generate string by using urldata\n",
    "    kavel_url = base_url + '?' + urllib.parse.urlencode(urldata)\n",
    "\n",
    "    return kavel_url\n",
    "\n",
    "# example\n",
    "ids = [\n",
    "    f'K{DATE[2:4]}00{month_counter}1800', \n",
    "    f'K{DATE[2:4]}00{month_counter}1801', \n",
    "    f'K{DATE[2:4]}00{month_counter}1900', \n",
    "    f'K{DATE[2:4]}00{month_counter}1901', \n",
    "    f'K{DATE[2:4]}00{month_counter}1000', \n",
    "    f'K{DATE[2:4]}00{month_counter}1001'\n",
    "]\n",
    "if OPBOD:\n",
    "    ids = [f'K{DATE[2:4]}{DATE[-2:]}01{id[-4:]}' for id in ids]\n",
    "\n",
    "for example_lot_id in ids:\n",
    "    example_url = URL\n",
    "    if 'add_veilingen' in locals():\n",
    "        _add_veiling = add_veilingen\n",
    "    else:\n",
    "        _add_veiling = False\n",
    "    print(get_kavel_url(OPBOD, example_url, _add_veiling, example_lot_id))\n",
    "    # if not OPBOD:\n",
    "    #     if int(month_counter) <= 12 and example_lot_id.endswith('1800'):\n",
    "    #         break\n",
    "    #     elif example_lot_id.endswith('1900'):\n",
    "    #         break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbconvert_instruction:remove_all_outputs"
    ]
   },
   "outputs": [],
   "source": [
    "def gettree(kavel_url, disp=False):\n",
    "    \n",
    "    '''\n",
    "    get html tree from string\n",
    "    '''\n",
    "    \n",
    "    import requests\n",
    "    import codecs\n",
    "    from lxml import html, etree\n",
    "    \n",
    "    # Request page\n",
    "    \n",
    "    req_success = False; c=0 # Try several times\n",
    "    \n",
    "    while req_success == False:\n",
    "        c+=1\n",
    "        \n",
    "        try:\n",
    "            page = requests.get(kavel_url)\n",
    "            if disp:\n",
    "                print(page, c)\n",
    "\n",
    "            # raise error within try if status is not OK (OK=200)\n",
    "            assert page.status_code == 200\n",
    "            \n",
    "            # Otherwise ok\n",
    "            req_success = True\n",
    "        \n",
    "        except KeyboardInterrupt:\n",
    "            raise\n",
    "        except:\n",
    "            if c == 1:\n",
    "                print('retry', end=',')\n",
    "            elif c > 100:\n",
    "                raise Exception(f'Retried {c} times, but failed')\n",
    "            else:\n",
    "                if c > 50:\n",
    "                    # Add extra pause after many tries\n",
    "                    time.sleep(c-50)\n",
    "                print(f'{c}', end='x')\n",
    "                req_success = False\n",
    "\n",
    "    # find encoding in header\n",
    "    DecodeType = page.headers[\"Content-type\"]\n",
    "    T = 'charset='\n",
    "    DecodeType = DecodeType[DecodeType.find(T)+len(T):]\n",
    "    # and convert to unicode\n",
    "    htmlstring = codecs.decode(page.content, DecodeType)\n",
    "    \n",
    "    # Convert string to tree object\n",
    "    tree = html.fromstring(htmlstring)\n",
    "    \n",
    "    return tree\n",
    "\n",
    "\n",
    "# Example\n",
    "gettree(\n",
    "    get_kavel_url(False, example_url, False, example_lot_id),\n",
    "    True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbconvert_instruction:remove_all_outputs"
    ]
   },
   "outputs": [],
   "source": [
    "class Lot:\n",
    "    \n",
    "    \n",
    "    def __init__(self, tree, OPBOD, disp=False):\n",
    "        self.tree = tree\n",
    "        self.OPBOD = OPBOD\n",
    "        self.disp = disp\n",
    "\n",
    "        # Has content? Price should be bold.\n",
    "        # if nothing is bold. Page may exist but results are not in yet.\n",
    "        paths = [\n",
    "            '//*[@id=\"content\"]/div[1]/div[1]/strong/text()',\n",
    "            '//*[@id=\"content\"]/div[1]/div[1]/b/text()',\n",
    "            '//*[@id=\"content\"]/div[1]/b/text()',\n",
    "            '//*[@id=\"content\"]/div[1]/p/b/text()', # <<- OPBOD needs this\n",
    "        ]\n",
    "        contents = [self.tree.xpath(path) for path in paths]\n",
    "        content = [c[0] for c in contents if len(c)>0]\n",
    "        \n",
    "        if len(content) > 0:\n",
    "            if content[0] == 'Niets gevonden.':\n",
    "                self.has_result = -1\n",
    "            else:\n",
    "                self.has_result = True\n",
    "        else:\n",
    "            self.has_result = False\n",
    "\n",
    "        \n",
    "    def __str__(self):\n",
    "        out = self.tree.xpath('/html/head/title/text()')\n",
    "        if hasattr(self, 'title_'):\n",
    "            out += [self.title_]\n",
    "        if hasattr(self, 'lot_index_'):\n",
    "            out += [self.lot_index_]\n",
    "        if hasattr(self, 'date_'):\n",
    "            out += [self.date_]\n",
    "        if hasattr(self, 'price_'):\n",
    "            out += [f'EUR {self.price_:6.0f}']\n",
    "            if hasattr(self, 'draw_') and (self.draw_):\n",
    "                out[-1] += ' (draw)'\n",
    "        if hasattr(self, 'nextlot_'):\n",
    "            out += [f'next [{self.nextlot_:4.0f}]']\n",
    "        if hasattr(self, 'images_'):\n",
    "            out += [f'{len(self.images_):3.0f} images']\n",
    "        if hasattr(self, 'text_'):\n",
    "            out += [f'{len(self.text_):3.0f} text lines']\n",
    "            \n",
    "        if self.has_result == -1:\n",
    "            out += ['no content.']\n",
    "        elif self.has_result == False:\n",
    "            out += ['no result.']\n",
    "        return ' | '.join(out)\n",
    "\n",
    "        \n",
    "    \n",
    "    def get_title(self):\n",
    "        \n",
    "        '''\n",
    "        Return title of this page. This can be found in a H4 with class name 'title'.\n",
    "        '''\n",
    "\n",
    "        path = '//h4[@class=\"title\"]/text()'\n",
    "        \n",
    "        self.title_ = self.tree.xpath(path)[0].strip()\n",
    "        \n",
    "        \n",
    "    def get_images(self):\n",
    "        \n",
    "        '''\n",
    "        Return urls (src) of images. These are inside divs of class 'photo'\n",
    "        '''\n",
    "        \n",
    "        lines = [item.get('src') for item in self.tree.xpath('//div[@class=\"photo\"]/a/img')]\n",
    "    \n",
    "        self.images_ = lines\n",
    "    \n",
    "    def get_text(self):\n",
    "        \n",
    "        '''\n",
    "        Just return all relevant text, which is in class 'catalogusdetailitem split-item-first'.\n",
    "        '''\n",
    "        \n",
    "        lines = self.tree.xpath('//div[@class=\"catalogusdetailitem split-item-first\"]/text()')\n",
    "        \n",
    "        self.text_ = lines\n",
    "        \n",
    "    def split_title(self):\n",
    "        \n",
    "        '''\n",
    "        Split title into fields:\n",
    "        year, month, counter, lotnr\n",
    "        '''\n",
    "        \n",
    "        if not hasattr(self, 'title'):\n",
    "            self.get_title()\n",
    "\n",
    "        lot_id = re.match('Kavel (.*)',self.title_).group(1)\n",
    "        if lot_id.startswith('K'):\n",
    "            #M = re.match('^K([0-9]{2})(00|01)(0[1-9]|1[0-2])([0-9]{4})$', lot_id)\n",
    "            #argout = tuple([M[i] for i in range(1, 5)])\n",
    "            # Added counter\n",
    "            #M = re.match('^K([0-9]{2})(00|01)((0|1)[1-9]|1[0-2])([0-9]{4})$', lot_id)\n",
    "            # Reorder fields if needed\n",
    "            fields = ['^',\n",
    "                      'K([0-9]{2})',         # K21 year\n",
    "                      '([0,1]{2})',          # 01, 00\n",
    "                      '([0-9]{2})',          # mm month\n",
    "                      '([0-9]{4})',          # iiii lotnr\n",
    "                      '$'\n",
    "            ]\n",
    "            if OPBOD:\n",
    "                fields = [fields[i] for i in [0,1,3,2,4,5]]\n",
    "            M = re.match(''.join(fields), lot_id)\n",
    "            if not OPBOD:\n",
    "                argout = tuple([M[i] for i in [1, 2, 3, 4]])\n",
    "            else:\n",
    "                argout = tuple([M[i] for i in [1, 3, 2, 4]])\n",
    "        else:\n",
    "            lot_nr = int(lot_id)\n",
    "            argout =(None, None, None, lot_nr)\n",
    "            \n",
    "        if self.disp: print(argout)\n",
    "\n",
    "       \n",
    "        return lot_id, *argout\n",
    "    \n",
    "    def get_date(self):\n",
    "        '''\n",
    "        Return date based on title\n",
    "        '''\n",
    "        _, yy, _, mm, _ = self.split_title()\n",
    "        \n",
    "        self.date_ = f'20{yy}-{mm}'\n",
    "    \n",
    "    def get_date_from_tree(self):\n",
    "        \n",
    "        '''\n",
    "        Return date of this auction by taking the title of the page.\n",
    "        This is pretty obsolete, because date is given at start of this notebook.\n",
    "        '''\n",
    "        \n",
    "        lines = self.tree.xpath('//title/text()')\n",
    "        date = lines[0]\n",
    "        \n",
    "        if 'Verkoop catalogus ' in date:\n",
    "            # title like \"Verkoop catalogus 2017-12\"\n",
    "            date = re.match('Verkoop catalogus (.*)',date)[1]\n",
    "\n",
    "        elif 'Verkoop bij inschrijving ' in date:\n",
    "            # title like \"Verkoop bij inschrijving 2019-0001 januari\"\n",
    "            M = re.match('Verkoop bij inschrijving (20[0-9]{2})-00([0-9]{2}).*',date)\n",
    "            date = '-'.join([M.group(1),M.group(2)])\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError(f'TODO: implement a date formatted as <{date}>.')\n",
    "       \n",
    "        self.date_ = date\n",
    "    \n",
    "    \n",
    "    def get_nextlot(self):\n",
    "        \n",
    "        '''\n",
    "        Return number of next lot by checking out the link to the next lot in the current page.\n",
    "        'K1900011801' will become 1801\n",
    "        '''\n",
    "        \n",
    "        xpath = r'//div[@class=\"catalogusdetailitem split-item-first\"]/div[2]/div[3]/a'\n",
    "        #xpath = r'//div[@class=\"catalogusdetailitem split-item-first\"]/div[3]/div[3]/a' # when auction is still active\n",
    "        \n",
    "        # link to next lot\n",
    "        Link = self.tree.xpath(xpath)\n",
    "        Tar = Link[0].get(\"href\")\n",
    "       \n",
    "        # extract lot name\n",
    "        nextLot = re.match('.*[\\?,\\&]meerfotos=(.*)(\\&.*)?',Tar).group(1)\n",
    "\n",
    "        if \"&veilingen=\" in nextLot:\n",
    "            nextLot = re.match('(.*)&',nextLot).group(1)\n",
    "            \n",
    "        # convert to integer\n",
    "        nextLot = int(nextLot[-4:])\n",
    "\n",
    "        if self.disp:\n",
    "            print(nextLot,Tar,etree.tostring(Link[0]))\n",
    "                \n",
    "        self.nextlot_ = nextLot\n",
    "    \n",
    "    def get_price(self):\n",
    "        \n",
    "        '''\n",
    "        Return price as float\n",
    "        '''\n",
    "\n",
    "        def get_price_opbod(self, price_line):\n",
    "            # Starts with status\n",
    "            if (len(price_line) == 1) and (price_line[0] == 'Deze kavel is gesloten.'):\n",
    "                print('closed')\n",
    "                return None\n",
    "            if len(price_line) < 1:\n",
    "                # fall back: no bold\n",
    "                price_line = [self.tree.xpath('//div[@class=\"catalogusdetailitem split-item-first\"]/text()')[0]]\n",
    "    \n",
    "            # Drop first\n",
    "            if price_line[0] == 'Deze kavel is gesloten.':\n",
    "                price_line = price_line[1:]\n",
    "            \n",
    "            if len(price_line) > 1:\n",
    "                print('Opbod has more than 1 prices. Take last')\n",
    "                print(price_line)\n",
    "            elif len(price_line) == 0:\n",
    "                print('Price not found, return None')\n",
    "                return None\n",
    "            \n",
    "            return price_line[-1] # Return scalar, not list\n",
    "                \n",
    "        def get_price_insch(self, price_line):\n",
    "            if len(price_line) == 0:\n",
    "                price_line = self.tree.xpath('//b/text()')\n",
    "                \n",
    "            if len(price_line) == 0:\n",
    "                print('Price not found, return None')\n",
    "                return None\n",
    "            return price_line[0] # Return scalar, not list        \n",
    "        \n",
    "        def parse_line(price_line):\n",
    "            tags = ['Zie kavel','Zie massakavel', 'Zie Kavel'] # part of combination lot\n",
    "            if any([t in price_line for t in tags]) :\n",
    "                price = 0\n",
    "            elif price_line == 'Niet gegund':\n",
    "                price = 0\n",
    "            else:\n",
    "                M = re.match(u'Gegund voor: \\u20ac *([0-9,.]*,[0-9]{2}) *\\(excl. alle eventuele bijkomende kosten en belastingen\\)', price_line)\n",
    "                if self.disp:print(M.group(0))\n",
    "                price = float(M.group(1).replace('.','').replace(',','.'))\n",
    "            return price\n",
    "\n",
    "        # Input error\n",
    "        if self.OPBOD is None:\n",
    "            raise ValueError('Set [OPBOD] before running this function.')\n",
    "        \n",
    "        # price can be bold or strong\n",
    "        price_line = self.tree.xpath('//div[@class=\"catalogusdetailitem split-item-first\"]/strong/text()')\n",
    "\n",
    "        if not self.OPBOD:\n",
    "            price_line = get_price_insch(self, price_line)\n",
    "        else:\n",
    "            price_line = get_price_opbod(self, price_line)\n",
    "            \n",
    "\n",
    "        if self.disp: print(price_line)\n",
    "            \n",
    "        if (price_line is None) or (len(price_line) == 0):\n",
    "            print('No price found! use 0 for now')\n",
    "            print(*self.tree.xpath('//*[@class=\"catalogusdetailitem split-item-first\"]/text()'))\n",
    "            price_line = 'Niet gegund'\n",
    "            raise Exception('Fix this')\n",
    "            \n",
    "        if price_line == 'Na loting':\n",
    "            price_line = self.tree.xpath('//strong/text()')[0]\n",
    "            Draw = True\n",
    "        else:\n",
    "            Draw = False        \n",
    "\n",
    "        Price = parse_line(price_line)\n",
    "\n",
    "        \n",
    "        self.price_ = Price\n",
    "        self.draw_ = Draw\n",
    "        \n",
    "        \n",
    "    def get_index(self):\n",
    "        \n",
    "        '''\n",
    "        Unique id to this lot. Includes date.\n",
    "        yyyy-mm-xxxx\n",
    "        '''\n",
    "        \n",
    "        _, yy, _, mm, lot_nr = self.split_title()\n",
    "        \n",
    "        self.lot_index_  = f'20{yy}-{mm}-{lot_nr}'\n",
    "        \n",
    "    def get_images_v1(self):\n",
    "        \n",
    "        '''\n",
    "        Return urls (src) of images. These are inside divs of class 'photo'\n",
    "        '''\n",
    "        \n",
    "        lines = [item.get('src') for item in self.tree.xpath('//div[@class=\"photo\"]/img')]\n",
    "            \n",
    "        self.images_ = lines\n",
    "\n",
    "    def get_nextlot_v1(self):\n",
    "        \n",
    "        '''\n",
    "        Return number of next lot by checking out the link to the next lot in the current page.\n",
    "        'K1900011801' will become 1801\n",
    "        \n",
    "        update 202007: layout changed. Link for next lot is in diffent div\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        # link to next lot\n",
    "        link = self.tree.xpath('//div[@class=\"catalogusdetailitem split-item-first\"]/div[4]/div[3]/a')\n",
    "        tar = link[0].get(\"href\")\n",
    "        \n",
    "        # extract lot name\n",
    "        nextLot = re.match('.*[\\?,\\&]meerfotos=(.*)(\\&.*)?', tar).group(1)\n",
    "\n",
    "        if \"&veilingen=\" in nextLot:\n",
    "            nextLot = re.match('(.*)&',nextLot).group(1)\n",
    "            \n",
    "        # convert to integer\n",
    "        nextLot = int(nextLot[-4:])\n",
    "\n",
    "        if self.disp:\n",
    "            print(nextLot, Tar, etree.tostring(Link[0]))\n",
    "                \n",
    "        self.nextlot_ = nextLot\n",
    "            \n",
    "# Example\n",
    "c = 0\n",
    "OK = False\n",
    "while OK == False:\n",
    "    try:\n",
    "        example_lot_id = ids[c]\n",
    "        kavel_url = get_kavel_url(OPBOD, example_url, _add_veiling, example_lot_id)\n",
    "        print(kavel_url)\n",
    "        tree = gettree(kavel_url, True)\n",
    "        Item = Lot(tree, OPBOD)\n",
    "        print(Item)\n",
    "        Item.disp\n",
    "        Item.get_index()\n",
    "        OK = True\n",
    "    except IndexError:\n",
    "        c = c + 1\n",
    "        if c > len(ids): raise RuntimeError\n",
    "        OK = False\n",
    "print(Item)\n",
    "Item.get_date()\n",
    "print(Item)\n",
    "Item.get_title()\n",
    "print(Item)\n",
    "Item.get_nextlot()\n",
    "print(Item)\n",
    "Item.get_images()\n",
    "print(Item)\n",
    "Item.get_text()\n",
    "print(Item)\n",
    "# This might throw an error if auction is still open\n",
    "Item.get_price()\n",
    "print(Item)\n",
    "Item.has_result, Item.price_, \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#auct_top\" id='auct_dl_results'><font size=+1><center>^^ TOP ^^</center></font></a>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get all results from all pages\n",
    "\n",
    "The \"**next lot**\" is linked in the current result. The function will look for this link and proceed. \n",
    "Because it is not know what the first lot will be, it is hard coded at `lot_counter = 1799`. \n",
    "It will increment with a step of `+1` to find the first lot.  \n",
    "Searching for next lots will continue untill the next lot has a **smaller** value that the current. This will cause the routine to stop when the last lot points back to the first lot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbconvert_instruction:remove_all_outputs"
    ]
   },
   "outputs": [],
   "source": [
    "# info\n",
    "print('+: add 1 to lot number\\n>: follow link to go to next\\nX: Done. Reached first lot in carousel\\n')\n",
    "\n",
    "DOLOOP = True; all_lots = dict()\n",
    "# first lot\n",
    "if OPBOD:\n",
    "    lot_counter = 999\n",
    "    lot_pat = 'K{:s}{:s}01{:.0f}' # 'K1809011800': Kyymm01llll\n",
    "else:\n",
    "    lot_counter = 1799\n",
    "    lot_pat = 'K{:s}00{:s}{:.0f}' # 'K1800091800': Kyy00mmllll\n",
    "    \n",
    "while DOLOOP:\n",
    "    all_lots[lot_counter] = dict()\n",
    "    # get lot\n",
    "    lot_id = lot_pat.format(DATE[2:4], month_counter, lot_counter)\n",
    "    lot_url = get_kavel_url(OPBOD, URL, EXTEND_URL, lot_id)\n",
    "    lot_tree = gettree(lot_url, disp = VERBOSE > 2)\n",
    "    lot_item = Lot(lot_tree, OPBOD)\n",
    "    \n",
    "    # continue with next if no content\n",
    "    if lot_item.has_result == -1:\n",
    "        next_lot = lot_counter + 1\n",
    "        print(lot_counter, end='+')\n",
    "        lot_counter = next_lot\n",
    "        continue\n",
    "\n",
    "    # find next number\n",
    "    try:\n",
    "        lot_item.get_nextlot()\n",
    "        next_lot = lot_item.nextlot_\n",
    "    except KeyboardInterrupt:\n",
    "        raise\n",
    "    except:\n",
    "        # Do not go to next, but try this one again\n",
    "        print(lot_url)\n",
    "        print('try again',end='>')\n",
    "        next_lot = lot_counter\n",
    "        lot_item.get_nextlot()\n",
    "\n",
    "        \n",
    "\n",
    "    # add current results to list\n",
    "    all_lots[lot_counter]['url'] = lot_url\n",
    "    all_lots[lot_counter]['item'] = lot_item\n",
    "    print(lot_counter, end='>')\n",
    "    \n",
    "    if VERBOSE > 2: print(lot_item)\n",
    "\n",
    "    if next_lot <= lot_counter :\n",
    "        # First lot_counter again. Break loop before entering a carousel\n",
    "        # If there is ony one lot. next_lot equals lot_counter\n",
    "        DOLOOP = False\n",
    "    else :\n",
    "        # continue with next_lot\n",
    "        lot_counter = next_lot\n",
    "\n",
    "print('X') # done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#auct_top\" id='auct_basic_parse'><font size=+1><center>^^ TOP ^^</center></font></a>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic parsing\n",
    "\n",
    "Simple stuff, without regex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbconvert_instruction:remove_all_outputs"
    ]
   },
   "outputs": [],
   "source": [
    "# Filter out empty lots\n",
    "all_lots = {k: v for k,v in all_lots.items() if 'item' in v}\n",
    "\n",
    "# Get indices and read info from tree\n",
    "lot_indices = []\n",
    "for lot_nr, lot in all_lots.items():\n",
    "    lot_item = lot['item']\n",
    "    lot_url = lot['url']\n",
    "    lot_item.get_title()\n",
    "    try:\n",
    "        lot_item.get_price()\n",
    "    except:\n",
    "        print('catch: no price ', end='')\n",
    "        lot_item.price_ = -1\n",
    "        lot_item.draw_ = False\n",
    "    lot_item.get_date()\n",
    "    lot_item.get_images()\n",
    "    lot_item.get_text()\n",
    "    lot_item.get_index()\n",
    "    if VERBOSE>0: print(lot_nr, lot_item)\n",
    "\n",
    "out = pd.DataFrame(\n",
    "    columns = ['Source', 'Title', 'Price', 'Draw', 'Raw_text', 'N_images', 'Images'],\n",
    "    index = [i['item'].lot_index_ for i in all_lots.values()],\n",
    "    data = {\n",
    "        'Source': [i['url'] for i in all_lots.values()],\n",
    "        'Title': [i['item'].title_ for i in all_lots.values()],\n",
    "        'Price': [i['item'].price_ for i in all_lots.values()],\n",
    "        'Draw': [i['item'].draw_ for i in all_lots.values()],\n",
    "        'Raw_text': [i['item'].text_ for i in all_lots.values()],\n",
    "#         'Images': [\n",
    "#             [re.sub('\\/catalog((us)|(i))','',baseurl) + jpg for jpg in i['item'].images] \n",
    "#             for i in all_lots.values()\n",
    "#         ],\n",
    "        'Images': [\n",
    "            [re.search(r'^http://.*?/',URL)[0] + jpg[1:] for jpg in i['item'].images_] # [1:] remove leading \"/\"\n",
    "            for i in all_lots.values()\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "out.N_images = out.Images.apply(len)\n",
    "out.loc[:, 'lot_counter'] = all_lots.keys()\n",
    "\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbconvert_instruction:remove_all_outputs"
    ]
   },
   "outputs": [],
   "source": [
    "# ran when auction was still open\n",
    "if (sum(out.Price == -1) / out.shape[0] > 0.8):\n",
    "    # add \"without-price\" to file name\n",
    "    NO_PRICE = True\n",
    "else:\n",
    "    NO_PRICE = False\n",
    "\n",
    "file_name = f'../data/drz-data-unparsed-{DATE}-{month_counter}.pkl'\n",
    "if NO_PRICE:\n",
    "    file_name = file_name.replace('.pkl', '-without-price.pkl')\n",
    "if OPBOD:\n",
    "    file_name = file_name.replace('.pkl', '-opbod.pkl')\n",
    "\n",
    "if (SKIPSAVE==False) and (not(os.path.isfile(file_name))):\n",
    "    print(file_name)\n",
    "    out.to_pickle(file_name)\n",
    "else:\n",
    "    print(f'Skip. {file_name} exists or saving is disabled in settings.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#auct_top\" id='auct_regex'><font size=+1><center>^^ TOP ^^</center></font></a>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In depth parsing\n",
    "Use `Raw_text` as input.  \n",
    "Modify regex files if fragment is not recognized.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read regex patterns\n",
    "import read_regex_patterns\n",
    "\n",
    "read_regex_patterns.read_tag_value()\n",
    "tags, flagtags, repfragments = read_regex_patterns.read_all()\n",
    "\n",
    "# Replace dataframe stored in memory with dataframe that was just saved to disk.\n",
    "file_name = f'../data/drz-data-unparsed-{DATE}-{month_counter}.pkl'\n",
    "if OPBOD:\n",
    "    file_name = file_name.replace('.pkl', '-opbod.pkl')\n",
    "out = pd.read_pickle(file_name)\n",
    "\n",
    "# # NB This might fail if \"drz-data-unparsed-{DATE}.pkl\" does not exist because price is not available yet and ran when auction was still open.\n",
    "# # It is safe to continue with the dataframe that is still in memory\n",
    "# file_name = file_name.replace('.pkl', '-without-price.pkl')\n",
    "# out = pd.read_pickle(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if '2022-02-4006' in out.index:\n",
    "    out.drop('2022-02-4006', inplace=True) # page is empty"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "file_name = '../data/pdf-data-unparsed-2014-10.pkl'\n",
    "out = pd.read_pickle(file_name)\n",
    "VERBOSE = 1\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbconvert_instruction:remove_all_outputs"
    ]
   },
   "outputs": [],
   "source": [
    "# parse raw text\n",
    "for IX in out.index :\n",
    "    \n",
    "    # find info\n",
    "    \n",
    "    rt = out.loc[IX,\"Raw_text\"]\n",
    "    \n",
    "    # first line:\n",
    "    \n",
    "    # Is it a draw?\n",
    "    Val = rt.pop(0) \n",
    "    if Val == 'Na loting':\n",
    "        Val = rt.pop(0) # val is now kavelnr\n",
    "        out.loc[IX,\"Draw\"] = True\n",
    "    else:\n",
    "        out.loc[IX,\"Draw\"] = False\n",
    "    \n",
    "    # when lot number is followed by an asteriks there is a note\n",
    "    if Val.endswith('*\\r'):\n",
    "        Val = Val[0:-2]\n",
    "        out.loc[IX,\"Note\"] = True\n",
    "    else :\n",
    "        Val = Val.strip()\n",
    "        out.loc[IX,'Note'] = False\n",
    "        \n",
    "    if VERBOSE>0:\n",
    "        print(Val)\n",
    "\n",
    "    # store lot nr        \n",
    "    out.loc[IX,\"LotNr\"]=Val\n",
    "    \n",
    "    \n",
    "    # second line\n",
    "    out.loc[IX,\"LotType\"]=rt.pop(0).strip()\n",
    "\n",
    "    # third line\n",
    "    Val = rt.pop(0).strip()\n",
    "    # This line is brand or optional line with type of lot\n",
    "    # All caps is brand\n",
    "    \n",
    "    # starts with 'Merk BRANDNAME'\n",
    "    if Val.startswith('Merk '):\n",
    "        Val = re.sub(r'^Merk ', '', Val)\n",
    "        \n",
    "    # It is not brand name. Add this Val to LotType\n",
    "    if Val in [\n",
    "        'Quad','Kampeerwagen/ camper','Pleziervaart motorvaartuig met opbouw en open kuip','Rubberboot','Kampeerwagen / camper'\n",
    "    ] or not Val.isupper():\n",
    "        out.loc[IX,\"LotType\"] += ''.join([' (' + Val + ')'])\n",
    "        if VERBOSE>0:print(Val, out.loc[IX,\"LotType\"])\n",
    "        if rt[0].isupper():\n",
    "            Val = rt.pop(0).strip() # next line is now brand name\n",
    "        else:\n",
    "            Val = ''\n",
    "        \n",
    "    out.loc[IX,\"ItemBrand\"]=Val\n",
    "\n",
    "    \n",
    "    \n",
    "    # escape characters, repair typos and translate \n",
    "    for i in range(len(rt)):\n",
    "        \n",
    "        # encode string as bytes\n",
    "        rt[i] = rt[i].encode('ascii',errors='xmlcharrefreplace')\n",
    "        \n",
    "        # replace text\n",
    "        for pat,sub in zip(repfragments.Pattern,repfragments.Replace):\n",
    "            rt[i] = re.sub(pat.encode('ascii',errors='xmlcharrefreplace'),sub.encode('ascii',errors='xmlcharrefreplace'),rt[i])\n",
    "        \n",
    "        # decode back to string, but special characters escaped to xml\n",
    "        rt[i]=rt[i].decode('ascii')\n",
    "\n",
    "    # Pull value after trailing or leading pattern (bgntag/endtag)\n",
    "    for Tag,Field in zip(tags.Pattern,tags.Field):\n",
    "        M = re.search(Tag,'\\n'.join(rt))\n",
    "        if M:\n",
    "            Val = M.group('val')\n",
    "            if VERBOSE>2:\n",
    "                print('\\t' + str(Field) + ' : ' + M.group(0).replace('\\n','[newline]') + '\\n\\t' + '|' + Val + '|')\n",
    "            # remove pattern and make rt a list again.\n",
    "            rt = '\\n'.join(rt).replace(M.group(0),'').split('\\n')\n",
    "        else:\n",
    "            Val = ''\n",
    "        out.loc[IX,Field] = Val        \n",
    "\n",
    "    # Pattern in full text? (flagtag)\n",
    "    for Tag,Field in zip(flagtags.Pattern,flagtags.Field):\n",
    "        # flagtags might occur more than once, hence a list of finditer results\n",
    "        Ms = list(re.finditer(Tag,'\\n'.join(rt)))\n",
    "        if Ms:\n",
    "            Val = True\n",
    "            for M in Ms:\n",
    "                if VERBOSE>2:\n",
    "                    print('\\t' + str(Field) + ' : ' + M.group(0).replace('\\n','[newline]') + '\\n\\t' + '|' + str(Val) + '|')\n",
    "                # remove pattern and make rt a list again.\n",
    "                rt = '\\n'.join(rt).replace(M.group(0),'').split('\\n')\n",
    "        else:\n",
    "            Val = False\n",
    "        out.loc[IX,Field] = Val\n",
    "\n",
    "        \n",
    "        \n",
    "    # loop trough remaining lines\n",
    "\n",
    "    for line in rt:\n",
    "               \n",
    "        # do comparison in bytes\n",
    "        line = line.encode('ascii',errors='xmlcharrefreplace')\n",
    "        if VERBOSE>2:\n",
    "            print(f'\\tremaining : {line}')\n",
    "            \n",
    "        # parsing\n",
    "        isParsed = False # some accounting: in the end this line should be parsed\n",
    "         \n",
    "        # line is empty.. skip .. next\n",
    "        if not line :# empty\n",
    "            isParsed = True\n",
    "            continue\n",
    "            \n",
    "        # line starting with '*' is a note\n",
    "        if out.loc[IX,'Note'] and line.startswith(bytes('*','ascii')):\n",
    "            if VERBOSE>2:\n",
    "                print('\\tNote:',end='')\n",
    "                print(out.loc[IX,'Note'],end='')\n",
    "                print(line)\n",
    "            Val = line[1:].decode('ascii')\n",
    "            out.loc[IX,'Note'] = Val\n",
    "            isParsed = True\n",
    "            continue\n",
    "        elif line.startswith(bytes('*','ascii')):\n",
    "            Val = line[1:].decode('ascii')\n",
    "            if Val.lower() in ['kavel is vervallen.', 'kavel vervallen.', 'deze kavel ']:\n",
    "                if VERBOSE>2:\n",
    "                    print('\\tNote:',end='')\n",
    "                    print(out.loc[IX,'Note'],end='')\n",
    "                    print(line)\n",
    "                out.loc[IX,'Note'] = Val\n",
    "                isParsed = True\n",
    "                continue            \n",
    "            elif VERBOSE>2:\n",
    "                print('Is this line not a NB?')\n",
    "                print(line)\n",
    "                raise\n",
    "                \n",
    "        if isParsed == False:\n",
    "            line = line.decode('ascii')\n",
    "            \n",
    "            # create empty string if not exist\n",
    "            if (\n",
    "                'SupInfo' not in out.loc[IX].index\n",
    "            ) or (\n",
    "                (\n",
    "                    not isinstance(out.loc[IX,'SupInfo'], str)\n",
    "                ) and (\n",
    "                    pd.isna(out.loc[IX,'SupInfo'])\n",
    "                )\n",
    "            ):\n",
    "                out.loc[IX,'SupInfo'] = ''\n",
    "            out.loc[IX,\"SupInfo\"] = '\\n'.join([out.loc[IX,'SupInfo'] , str(line)])\n",
    "            if ('prev_ix' in locals()) and (IX == prev_ix):\n",
    "                print(''.join([' '] * len(IX)), end='')\n",
    "            else:\n",
    "                print(str(IX), end='')\n",
    "            print(f'[{line:s}]')\n",
    "            prev_ix = str(IX)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "file_name = file_name.replace('-unparsed', '')\n",
    "\n",
    "if (SKIPSAVE==False) and (not(os.path.isfile(file_name))):\n",
    "    print(file_name)\n",
    "    out.to_pickle(file_name)\n",
    "else:\n",
    "    print(f'Skip. {file_name} exists or saving is disabled in settings.')\n",
    "\n",
    "raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#auct_top\" id='auct_save'><font size=+1><center>^^ TOP ^^</center></font></a>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save results to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbconvert_instruction:remove_all_outputs"
    ]
   },
   "outputs": [],
   "source": [
    "file_name = f'../data/drz-data-{DATE}-{month_counter}.pkl'\n",
    "if NO_PRICE:\n",
    "    file_name = file_name.replace('.pkl', '-without-price.pkl')\n",
    "if OPBOD:\n",
    "    file_name = file_name.replace('.pkl', '-opbod.pkl')\n",
    "if (SKIPSAVE==False) and (not(os.path.isfile(file_name))):\n",
    "    print(file_name)\n",
    "    out.to_pickle(file_name)\n",
    "else:\n",
    "    print(f'Skip. {file_name} exists or saving is disabled in settings.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next: add rdw data\n",
    "\n",
    "Because rdw data changes constantly it is advisable to run the notebook that adds rdw data to the above results soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbconvert_instruction:remove_all_outputs"
    ]
   },
   "outputs": [],
   "source": [
    "assert False, 'stop running, below is sandbox'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', 100):\n",
    "    display(out.tail(1).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = '../data/drz-data-{}.pkl'.format(DATE)\n",
    "out2 = pd.read_pickle(file_name)\n",
    "out.drop(columns='lot_counter').fillna('nn').equals(out2.fillna('nn'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(\n",
    "    np.setdiff1d(out.columns, out2.columns),\n",
    "    np.setdiff1d(out2.columns, out.columns)\n",
    ")\n",
    "print(\n",
    "    np.setdiff1d(out.index, out2.index),\n",
    "    np.setdiff1d(out2.index, out.index)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iseq = out.drop(columns='lot_counter').fillna('nn').eq(out2.fillna('nn'))\n",
    "print(\n",
    "    out.drop(columns='lot_counter').index[(iseq == False).any(axis=1)],\n",
    "    out.drop(columns='lot_counter').columns[(iseq == False).any(axis=0)]\n",
    ")\n",
    "col = 'Images'\n",
    "pd.concat([\n",
    "    out.loc[iseq[col] == False, col],\n",
    "    out2.loc[iseq[col] == False, col]    \n",
    "], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test regex on misbehaving fragment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "p = flagtags.set_index('Field').loc['rhd', 'Pattern']\n",
    "print(p, end='\\n\\n')\n",
    "p='''(?i)lpg( g3( gas ?installatie)?)?( \\(liquified\\spetroleum\\sgas\\))?\\n'''\n",
    "s = '''2015-01-8149[stuur rechts]\n",
    "'''\n",
    "\n",
    "s = re.sub('(\\n?)[0-9, ,\\-]{0,12}\\[', r'\\1', re.sub('\\](\\n?)', r'\\1', s))\n",
    "print(s.format())\n",
    "M = re.search(p,s)\n",
    "if M:\n",
    "    print(M[0])\n",
    "else:\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "p = tags.set_index('Field').loc['OpH', 'Pattern']\n",
    "print(p,end='\\n\\n')\n",
    "p = r'(?<! )([A,a]fgelezen )?[D,d]raaiuren(stand)?[:, ] *(?P<val>([0-9,\\.,\\s]+)|(onbekend))( ?uur)?'\n",
    "s = '2015-02-7359[afgelezen draaiuren 3.045]'\n",
    "s = re.sub('(\\n?)[0-9, ,\\-]{0,12}\\[', r'\\1', re.sub('\\](\\n?)', r'\\1', s))\n",
    "print(s.format())\n",
    "M = re.search(p,s)\n",
    "if M:\n",
    "    print(M[0])\n",
    "else:\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M.groups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = out.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"/home/tom/data/satdatsci-data-link/cars-from-all-auctions.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep = df0.query(\"Reg != ''\").reset_index().merge(df.reset_index(), on='Reg', how='inner')\n",
    "\n",
    "\n",
    "rep.groupby(['index_x', 'index_y']).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
