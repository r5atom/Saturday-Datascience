{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8095846-35d3-458d-8aa5-9f625e88fe95",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<a id='pred_top'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f58592-a440-408f-b81d-4bcba608d199",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Predict auction price\n",
    "\n",
    "Try several models and improve predicition accuracy\n",
    "\n",
    "## Model fitting\n",
    "\n",
    "- Linear fits  \n",
    "  1. [Simple linear fit](#pred_model_1)  \n",
    "     No cross validation. Observations with missing values are dropped.\n",
    "  2. [Dependent values scaled](#pred_model_2)  \n",
    "     Dependent value here is _prices_.\n",
    "  3. [Partial data](#pred_model_3)  \n",
    "     Only young cars\n",
    "- Multiple linear regression models  \n",
    "  1. [MLR fit without imputation](#pred_model_4)  \n",
    "  2. [With imputation](#pred_model_5)  \n",
    "  3. [Include categorical features](#pred_model_6)  \n",
    "  4. [Lasso regularization](#pred_model_7)  \n",
    "  5. [include engineered features](#pred_model_8)\n",
    "\n",
    "## Results\n",
    "\n",
    "- [Model performance](#pred_accuracies)\n",
    "- [Save best model](#pred_save_model) **TODO**  \n",
    "  This is not implemented yet. Some preprocessing functions are not handled well with `pickle`.\n",
    "- [Predictions](#pred_predict)\n",
    "     \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "688f0ffa-ba7f-49b3-89ec-ffca409eb13c",
   "metadata": {
    "lines_to_next_cell": 2,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32a92413-5ba6-4716-a91a-234954a9cb6d",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kind': 'opbod', 'id': '2025-0601', 'date': '20250607'}\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(cfg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAUCTION\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cfg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAUCTION\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopbod\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n\u001b[1;32m      8\u001b[0m OPBOD \u001b[38;5;241m=\u001b[39m cfg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAUCTION\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopbod\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      9\u001b[0m AUCTION_ID \u001b[38;5;241m=\u001b[39m cfg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAUCTION\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with open('../assets/drz-settings-current.json', 'r') as fid:\n",
    "    cfg = json.load(fid)\n",
    "print(cfg['AUCTION'])\n",
    "\n",
    "if cfg['AUCTION']['kind'] == 'opbod':\n",
    "    raise NotImplementedError\n",
    "    \n",
    "OPBOD = cfg['AUCTION']['kind'] == 'opbod'\n",
    "AUCTION_ID = cfg['AUCTION']['id']\n",
    "DATA_DIR = cfg['FILE_LOCATION']['data_dir']\n",
    "RESULTS_DIR = cfg['FILE_LOCATION']['report_dir']\n",
    "VERBOSE = int(cfg['GENERAL']['verbose'])\n",
    "SAVE_METHOD = cfg['GENERAL']['save_method']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45590502-c707-4878-91c7-d851a244c7bc",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if SAVE_METHOD == 'skip_when_exist':\n",
    "    do_save = lambda fn: not(os.path.isfile(fn))\n",
    "elif SAVE_METHOD == 'always_overwrite':\n",
    "    do_save = lambda _: True\n",
    "elif SAVE_METHOD == 'skip_save':\n",
    "    do_save = lambda _: False\n",
    "else:\n",
    "    raise NotImplementedError(f'SAVE_METHOD: {SAVE_METHOD} not implemented')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92588839-3c77-434f-a26e-fb5b61e1b04c",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SAVE_METHOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0815e94-ee9b-4fa0-b23c-00dcdde10d18",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TAG_SINGLE = \"nbconvert_instruction:remove_single_output\"\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "639ecb11-deb2-465f-be33-4cdf86b92d40",
   "metadata": {
    "raw_mimetype": "",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "import os\n",
    "# setting path\n",
    "os.chdir(r'..')\n",
    "\n",
    "import drz_config\n",
    "cfg = drz_config.read_config()\n",
    "VERBOSE = cfg['VERBOSE']\n",
    "SKIPSAVE = cfg['SKIPSAVE']\n",
    "\n",
    "if VERBOSE > 0:\n",
    "    display(cfg)\n",
    "\n",
    "if cfg['OPBOD']:\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c186f091-f149-4c15-bfc3-1264c7f266e6",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b86898-a3fe-4188-b242-481f82aa9abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.__version__, np.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0952bfc4-88e1-467f-a477-623820a199ce",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set figure defaults (needs to be in cell seperate from import sns)\n",
    "plt.style.use([\n",
    "    'default',\n",
    "    f\"{cfg['FILE_LOCATION']['app_dir']}/assets/movshon.mplstyle\",\n",
    "    f\"{cfg['FILE_LOCATION']['app_dir']}/assets/context-notebook.mplstyle\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43968054-4f8a-4713-8c4a-681deb243a0c",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08784976-dc7d-4826-8dac-8a258f0dbc18",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fn = f'{DATA_DIR}/cars-for-ml.pkl'\n",
    "print(fn)\n",
    "df = pd.read_pickle(fn)\n",
    "print(df.shape)\n",
    "\n",
    "# time deltas\n",
    "sel = (df.dtypes == 'timedelta64[ns]') | (df.columns == 'age_at_import')\n",
    "df.loc[:, sel] = df.loc[:, sel].applymap(lambda x: x.days).astype('Float64')\n",
    "# nullable boolean\n",
    "sel = df.dtypes == 'boolean'\n",
    "df.loc[:,sel] = df.loc[:,sel].astype('O').fillna(np.nan)\n",
    "# int to float\n",
    "df.price = df.price.astype('Float64')\n",
    "# categories\n",
    "cat_columns = ['brand', 'model', 'fuel', 'body_type','color', 'energy_label', 'fourwd', 'automatic_gearbox', 'under_survey']\n",
    "# numerical\n",
    "num_columns = list(np.setdiff1d(df.columns, cat_columns + ['price']))\n",
    "df.loc[:, num_columns] = df.loc[:, num_columns].astype('Float64')\n",
    "\n",
    "# Factorized categorical values\n",
    "fld = 'energy_label'\n",
    "# replace empty with NaN creates factor '-1'\n",
    "v, idx = pd.factorize(df[fld].replace({'': np.nan}), sort=True)\n",
    "# convert '-1' back to NaN\n",
    "v = v.astype(float)\n",
    "v[v==-1] = np.nan\n",
    "# Store in dataframe\n",
    "new_col = 'converted_' + fld\n",
    "df[new_col] = v\n",
    "# update list\n",
    "num_columns += [new_col]\n",
    "cat_columns.remove(fld)\n",
    "print('\\nCategorical field [{}] is converted to sequential numbers with: '.format(fld), end='\\n\\t')\n",
    "print(*['{} <'.format(c) for c in idx], end='\\n\\n')\n",
    "\n",
    "# convert boolean to string\n",
    "for fld in ['fourwd', 'automatic_gearbox', 'under_survey']:\n",
    "    if fld not in df.columns:\n",
    "        print(f'!{fld} not in data!. Skip for now')\n",
    "        continue\n",
    "    new_col = fld\n",
    "    # # update list\n",
    "    # cat_columns += [new_col]\n",
    "    # cat_columns.remove(fld)\n",
    "    replace_dict = {\n",
    "        '': '', \n",
    "        True: 'y', \n",
    "        False: 'n'\n",
    "    }\n",
    "    df[new_col] = df[fld].astype('O').replace(replace_dict)\n",
    "    print('\\nBoolean field [{}] is converted to numbers according to: '.format(fld), end='\\n')\n",
    "    print(*['\\t\"{}\" -> {} ({})\\n'.format(k,v, type(v)) for k,v in replace_dict.items()], end='\\n\\n')\n",
    "\n",
    "# convert integer to float and replace -1\n",
    "for fld in ['number_of_cylinders', 'number_of_doors', 'number_of_gears', 'number_of_seats']:\n",
    "    if fld not in df.columns:\n",
    "        print(f'!{fld} not in data!. Skip for now')\n",
    "        continue\n",
    "    new_col = fld\n",
    "    replace_dict = {\n",
    "        -1: np.nan, \n",
    "    }\n",
    "    df[new_col] = df[fld].replace(replace_dict).astype(float)\n",
    "\n",
    "# convert empty string to NaN\n",
    "for fld in ['brand', 'model', 'fuel', 'body_type', 'color', 'fourwd']:\n",
    "    if fld not in df.columns:\n",
    "        print(f'!{fld} not in data!. Skip for now')\n",
    "        continue\n",
    "    new_col = fld\n",
    "    replace_dict = {\n",
    "        '': np.nan, \n",
    "    }\n",
    "    df[new_col] = df[fld].replace(replace_dict)\n",
    "\n",
    "# translate Dutch to English\n",
    "fld = 'color'\n",
    "new_col = fld\n",
    "# # update list\n",
    "# cat_columns += [new_col]\n",
    "# cat_columns.remove(fld)\n",
    "replace_dict = {\n",
    "    '': 'missing', \n",
    "    'BLAUW': 'Blue',\n",
    "    'ROOD': 'Red',\n",
    "    'GROEN': 'Green',\n",
    "    'GRIJS': 'Gray',\n",
    "    'WIT': 'White',\n",
    "    'ZWART': 'Black',\n",
    "    'BEIGE': 'Beige',\n",
    "    'BRUIN': 'Brown',\n",
    "    'ROSE': 'Pink',\n",
    "    'GEEL': 'Yellow',\n",
    "    'CREME': 'Creme',\n",
    "    'ORANJE': 'Orange',\n",
    "    'PAARS': 'Purple'\n",
    "}\n",
    "df[new_col] = df[fld].replace(replace_dict)\n",
    "print('\\nField [{}] is converted according to: '.format(fld), end='\\n')\n",
    "print(*['\\t\"{}\" -> {} ({})\\n'.format(k,v, type(v)) for k,v in replace_dict.items()], end='\\n\\n')\n",
    "\n",
    "# reporting\n",
    "try:\n",
    "    print('Categorical:', len(cat_columns))\n",
    "    [print('\\t[{:2.0f}] {:s}'.format(i+1, c)) for i,c in enumerate(df[cat_columns].columns)]\n",
    "    print('Numercial:', len(num_columns))\n",
    "    [print('\\t[{:2.0f}] {:s}'.format(i+1, c)) for i,c in enumerate(df[num_columns].columns)]\n",
    "    print('Last lot in data set:\\n\\t{}'.format(df.index[-1]))\n",
    "except:\n",
    "    cat_columns = [c for c in cat_columns if c in df.columns]\n",
    "    num_columns = [c for c in num_columns if c in df.columns]    \n",
    "    print('! not all fields are in data !. Skip for now')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c1cafa-1c82-469a-99da-123237cbdfe7",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Store model results in dictonary: Instantiate empty dict\n",
    "models = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e780eb-c77f-46e9-ba41-7b039e240dfa",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_shelve_vars():\n",
    "    import types\n",
    "    to_shelve = {}\n",
    "    not_to_shelve = {}\n",
    "\n",
    "    # loop over global variables (within this function is ignored)\n",
    "    for var,val in globals().items():\n",
    "        \n",
    "        # skip variables based on names\n",
    "        if re.match('^_(\\d+|(i+\\d*))$', var) is not None:\n",
    "            not_to_shelve[var] = '-n'\n",
    "            continue\n",
    "        if re.match('^_+$', var) is not None:\n",
    "            not_to_shelve[var] = '---'\n",
    "            continue\n",
    "        if var in ('_dh', '_ih', '_oh'):\n",
    "            not_to_shelve[var] = '-dio'\n",
    "            continue\n",
    "        if var in ('In', 'Out'):\n",
    "            not_to_shelve[var] = '-io'\n",
    "            continue\n",
    "        if var in ('__doc__', '__loader__', '__name__', '__package__', '__session__', '__spec__'):\n",
    "            not_to_shelve[var] = val\n",
    "            continue\n",
    "        \n",
    "        # skip built-ins and modules\n",
    "        if isinstance(globals()[var], (types.ModuleType, types.BuiltinFunctionType, types.FunctionType)):\n",
    "            not_to_shelve[var] = type(globals()[var])\n",
    "            continue\n",
    "        else:\n",
    "            pass\n",
    "            #print(globals()[var].__class__, var)\n",
    "\n",
    "        # store\n",
    "        to_shelve[var] = val\n",
    "        \n",
    "    return not_to_shelve, to_shelve\n",
    "    \n",
    "drop,keep = split_shelve_vars()\n",
    "list(keep.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d82767-3917-4c5d-b1ae-1abe7418b8da",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "keep.pop('get_ipython')\n",
    "keep.pop('exit')\n",
    "keep.pop('quit')\n",
    "keep.pop('fid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85386272-f4ca-4c9c-aa64-a2aa92b49a9b",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shelve\n",
    "from inspect import getsource\n",
    "import types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e28d99a-4b11-4884-b43a-90f8d686fd7c",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with shelve.open('./predict-price.shelve', flag='n') as slf:\n",
    "    for k in [\n",
    "        'cfg',\n",
    "        #'OPBOD',\n",
    "        #'AUCTION_ID',\n",
    "        #'DATA_DIR',\n",
    "        'RESULTS_DIR',\n",
    "        #'VERBOSE',\n",
    "        #'SAVE_METHOD',\n",
    "        #'TAG_SINGLE',\n",
    "        #'fn',\n",
    "        'df',\n",
    "        'cat_columns',\n",
    "        'num_columns',\n",
    "        'models',\n",
    "        'do_save']:\n",
    "        print(k)\n",
    "        if k in keep:\n",
    "            v = keep[k]\n",
    "        else:\n",
    "            v = globals()[k]\n",
    "            if isinstance(v, types.FunctionType):\n",
    "                src = getsource(v).strip()\n",
    "                cnt = len([k for k in slf.keys() if k.startswith('def')])\n",
    "                k = f'def{cnt}:'\n",
    "                v = src\n",
    "            \n",
    "        slf[k] = v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2051415-4b69-425a-bd0b-91f1d8ffd907",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove_when_contains:image"
    ]
   },
   "outputs": [],
   "source": [
    "for m in range(1,9):\n",
    "    nb = f\"./predict-price-model{m}.ipynb\"\n",
    "    display({'text/html':f'<HR><h3>Running {nb}</h3><hr>'}, raw=True)\n",
    "    %run {nb}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37be37a-9b01-4fbb-8677-96830c9cd281",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with shelve.open('./predict-price.shelve', flag='r') as slf:\n",
    "    for k,v in slf.items():\n",
    "        print(k)\n",
    "        globals()[k] = v\n",
    "        if re.match('def\\d+:', k) is not None:\n",
    "            print(v)\n",
    "            exec(v) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2288f6-b8ce-40c6-9da5-e533c01b29bf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove_when_contains:image"
    ]
   },
   "outputs": [],
   "source": [
    "# Best model\n",
    "model_name = 'MLR added features'\n",
    "\n",
    "# Display prediction errors\n",
    "\n",
    "x_sample = df.dropna(subset=['price']).iloc[:,1:]\n",
    "y_sample = df.dropna(subset=['price']).iloc[:,0]\n",
    "# Add features\n",
    "x_sample.loc[:,'usage_intensity'] = x_sample.odometer / x_sample.age\n",
    "x_sample.loc[:,'classic'] = x_sample.age > 25*365\n",
    "x_sample.loc[:,'classic'] = x_sample.loc[:,'classic'].astype('O').replace({True:'y', False:'n'})\n",
    "#x_sample.loc[:,'youngtimer'] = (x_sample.age > 15*365) & (x_sample.age <= 25*365)\n",
    "#x_sample.loc[:,'youngtimer'].replace({True:'y', False:'n'}, inplace=True)\n",
    "x_sample[pd.isna(x_sample)] = np.nan\n",
    "# predict again\n",
    "y_sample_pred = models[model_name]['model'].predict(x_sample) \n",
    "\n",
    "x_sample['price'] = y_sample\n",
    "x_sample['prediction_error'] = y_sample_pred - y_sample\n",
    "x_sample['prediction_error_fraction'] = y_sample_pred/y_sample\n",
    "x_sample['prediction_error_log'] = np.log10(x_sample.prediction_error_fraction)\n",
    "x_sample['prediction_error_abslog'] = np.abs(np.log10(x_sample.prediction_error_fraction))\n",
    "x_sample['prediction'] = y_sample_pred\n",
    "x_sample['age_y'] = x_sample.age/365\n",
    "\n",
    "\n",
    "# Note some are close to perfect, because they are in training set and are unique in brand etc\n",
    "print(f'best predictons of [{model_name}] model')\n",
    "display(x_sample.sort_values(by='prediction_error_abslog').head(16).T)\n",
    "print('worst predictions')\n",
    "display(x_sample.sort_values(by='prediction_error_abslog').tail(16).T)\n",
    "print('largest underestimate')\n",
    "display(x_sample.sort_values(by='prediction_error').head(16).T)\n",
    "print('largest overestimate')\n",
    "display(x_sample.sort_values(by='prediction_error').tail(16).T)\n",
    "print('worst prediction recent auction')\n",
    "is_last_auction = x_sample.index.str.startswith('-'.join(x_sample.index[-1].split('-')[:2]))\n",
    "display(x_sample[is_last_auction].sort_values(by='prediction_error_abslog').tail(8).T)\n",
    "\n",
    "plt.figure(figsize=[8,8])\n",
    "plt.plot(x_sample.age_y, x_sample.prediction_error_log, color='k', marker='s', markeredgecolor = (0, 0, 0, 0), markerfacecolor = (0, 0, 0, 1), linestyle='None', ms=1)\n",
    "plt.axhline(0, lw=2, linestyle='--', color ='k')\n",
    "plt.xlabel('age [years]')\n",
    "plt.ylabel('prediction error [log of fraction]\\n(positive: prediction overestimates)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1c490a-97f8-46a3-b820-feea21d77a8a",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Model accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186db7d2-0a8c-4dff-8551-6e80ab79748d",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove_when_contains:image"
    ]
   },
   "outputs": [],
   "source": [
    "# plot R^2\n",
    "\n",
    "# counter for x-offset\n",
    "c=0\n",
    "\n",
    "# figure\n",
    "fig = plt.figure(figsize=[4,2])\n",
    "ax = fig.gca()\n",
    "xs = ys = fs = np.empty(0)\n",
    "\n",
    "# loop over all models\n",
    "for name,res in models.items():\n",
    "\n",
    "    c+=1 # x-offset\n",
    "\n",
    "    if name == 'linear regression no cv':\n",
    "        # No cv, so only one value. Make it a list of one for type consistency\n",
    "        k = 'R^2'\n",
    "        rsq = [res[k]]\n",
    "    \n",
    "    else: \n",
    "        k = 'cv R^2'\n",
    "        rsq = res[k]\n",
    "        \n",
    "    if 'n betas effective' in res:\n",
    "        ndf = res['n betas effective']\n",
    "    elif 'betas' in res:\n",
    "        ndf = len(res['betas'])\n",
    "    elif 'n effective features' in res:\n",
    "        ndf = res['n effective features']\n",
    "        \n",
    "    # add r-squares and offset to vectors\n",
    "    ys = np.concatenate([ys, rsq])\n",
    "    xs = np.concatenate([xs, np.ones_like(rsq) * c])\n",
    "    fs = np.concatenate([fs, [ndf]])\n",
    "\n",
    "# actual plotting\n",
    "sns.swarmplot(x=xs, y=ys, ax=ax, hue=None)\n",
    "ax.bar(range(0,len(models)), [res['R^2'] for res in models.values()], width=0.8, fc='none')\n",
    "for x,ndf in enumerate(fs):\n",
    "    if ndf is None:\n",
    "        continue\n",
    "    if x == 0:\n",
    "        s = f'd.f.: {ndf:.0f}'\n",
    "    else:\n",
    "        s = f'{ndf:.0f}'\n",
    "    ax.text(x, 1, s, ha='center')\n",
    "# prettify\n",
    "ax.set_xticks(range(0,len(models)))\n",
    "ax.set_xticklabels(labels=list(models.keys()), rotation=45, va='top', ha='right', style='italic')\n",
    "ax.set_ylim(bottom=0, top=+1)\n",
    "ax.set_title('Model performance\\n', style='italic')\n",
    "ax.set_ylabel('Coefficient of determination\\n($R^2$)', style='italic')\n",
    "ax.xaxis.set_tick_params(which='minor', bottom=False)\n",
    "\n",
    "# save\n",
    "file_name = f\"{RESULTS_DIR}/model-performance.png\"\n",
    "if True | do_save(file_name): # always save\n",
    "    print(file_name)\n",
    "    with plt.style.context(f\"{cfg['FILE_LOCATION']['app_dir']}/assets/context-paper.mplstyle\"):\n",
    "        plt.savefig(file_name, bbox_inches='tight', transparent=False)\n",
    "else:\n",
    "    plt.show()\n",
    "    print(f'Skip. {file_name} exists or saving is disabled in settings.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddad3c4-99c4-4ed7-abcd-c5ff5224af10",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove_when_contains:image"
    ]
   },
   "outputs": [],
   "source": [
    "# plot data\n",
    "\n",
    "# loop over all models\n",
    "for model_name in models.keys():\n",
    "    print(model_name)\n",
    "    res = models[model_name]\n",
    "    features = num_columns.copy()\n",
    "    \n",
    "    # model specific adjustments\n",
    "    if (model_name == 'linear regression log price') \\\n",
    "    or (model_name == 'linear regression log price young'):\n",
    "        yX = df.loc[:,['price', 'age']].dropna()\n",
    "        X = yX.iloc[:,1]\n",
    "        y = yX.iloc[:,0]\n",
    "        X[pd.isna(X)] = np.nan\n",
    "        # log price is used\n",
    "        y = np.log10(y)\n",
    "        # unit\n",
    "        unit = '(log[EUR])'\n",
    "    elif (model_name == 'MLR reduced observations') \\\n",
    "    or (model_name == 'MLR impute median'):\n",
    "        yX = df.dropna(subset=['price'] + features).loc[:,['price'] + features]\n",
    "        X = yX.iloc[:,1:]\n",
    "        y = np.log10(yX.iloc[:,0])\n",
    "        X[pd.isna(X)] = np.nan\n",
    "        unit = '(log[EUR])'\n",
    "    elif (model_name == 'MLR with categorical') \\\n",
    "    or (model_name == 'MLR Lasso'):\n",
    "        yX = df.dropna(subset=['price']).copy()\n",
    "        X = yX.iloc[:,1:]\n",
    "        y = yX.iloc[:,0]\n",
    "        X[pd.isna(X)] = np.nan\n",
    "        unit = '(EUR)'\n",
    "    elif (model_name == 'MLR added features'):\n",
    "        yX = df.dropna(subset=['price']).copy()\n",
    "        X = yX.iloc[:,1:]\n",
    "        y = yX.iloc[:,0]\n",
    "        X[pd.isna(X)] = np.nan\n",
    "        unit = '(EUR)'\n",
    "        X.loc[:,'usage_intensity'] = X.odometer / X.age\n",
    "        X.loc[:,'classic'] = X.age > 25*365\n",
    "        X.loc[:,'classic'] = X.loc[:,'classic'].astype('O').replace({True:'y', False:'n'})\n",
    "        X[pd.isna(X)] = np.nan\n",
    "    elif (model_name == 'Decision Tree Regression'):\n",
    "        yX = df.dropna(subset=['price']).copy()\n",
    "        X = yX.iloc[:,1:]\n",
    "        y = yX.iloc[:,0]\n",
    "        X[pd.isna(X)] = np.nan\n",
    "        unit = '(EUR)'\n",
    "        X.loc[:,'usage_intensity'] = X.odometer / X.age\n",
    "        X.loc[:,'classic'] = X.age > 25*365\n",
    "        X.loc[:,'classic'] = X.loc[:,'classic'].astype('O').replace({True:+1, False:-1, np.nan:0}, inplace=True)\n",
    "        for col in ['fourwd', 'under_survey', 'automatic_gearbox']:\n",
    "            X.loc[:, col].replace({'n':0, 'y':1}, inplace=True)\n",
    "            \n",
    "    else:\n",
    "        # all original data\n",
    "        yX = df.loc[:,['price', 'age']].dropna()\n",
    "        X = yX.iloc[:,1]\n",
    "        y = yX.iloc[:,0]\n",
    "        X[pd.isna(X)] = np.nan\n",
    "        unit = '(EUR)'\n",
    "    \n",
    "    if X.ndim != 1:\n",
    "        n_feat = X.shape[1]\n",
    "    else:\n",
    "        n_feat = 1\n",
    "        \n",
    "    if not model_name in ('MLR with categorical', 'MLR Lasso', 'MLR added features', 'Decision Tree Regression'):\n",
    "        # needed for .predict\n",
    "        X = np.array(X).reshape(-1,n_feat)\n",
    "        y = np.array(y).reshape(-1,1)\n",
    "    \n",
    "    # predict all data\n",
    "    y_pred = res['model'].predict(X)\n",
    "    if max(y) < 10:\n",
    "        rmse = np.sqrt(np.mean(((10**y)-(10**y_pred))**2))\n",
    "    else:\n",
    "        rmse = np.sqrt(np.mean((y-y_pred)**2))\n",
    "    print(rmse)\n",
    "\n",
    "    # actual plotting\n",
    "    fig,axs = plt.subplots(nrows=2, ncols=1, figsize=[8,8])\n",
    "    \n",
    "    # data\n",
    "    axs[0].plot(y, y_pred, marker=',', linestyle='None')\n",
    "    # error\n",
    "    axs[1].plot(y, y_pred-y, marker=',', linestyle='None')\n",
    "    \n",
    "    # axis equal for top\n",
    "    if (model_name == 'MLR with categorical') or (model_name == 'MLR Lasso') or (model_name == 'MLR added features') or (model_name == 'Decision Tree Regression'):\n",
    "        axs[0].set_xscale('log')\n",
    "        axs[0].set_yscale('log')\n",
    "        axs[1].set_xscale('log')\n",
    "    axs[0].set_aspect(1)\n",
    "    # store limits\n",
    "    yl = axs[0].get_ylim()\n",
    "    xl_top = axs[0].get_xlim()\n",
    "    xl_bot = axs[1].get_xlim()\n",
    "    xl = [np.max([xl_top[0], xl_bot[0]]), np.min([xl_top[1], xl_bot[1]])]\n",
    "    # plot unity line and 0 error\n",
    "    unity_line = [np.max([xl[0], yl[0]]), np.min([xl[1], yl[1]])]\n",
    "    axs[0].plot(unity_line, unity_line, '-k', linewidth=2)\n",
    "    axs[1].plot(xl, [0, 0], '-k', linewidth=2)\n",
    "    # reset limits\n",
    "    axs[0].set_xlim(xl)\n",
    "    axs[1].set_xlim(xl)\n",
    "\n",
    "    # make equal size panels\n",
    "    # Note: sharex did not work\n",
    "    bb=axs[0].get_position(False)\n",
    "    rect_top = bb.bounds\n",
    "    bb=axs[1].get_position(False)\n",
    "    rect_bot = bb.bounds\n",
    "    rect = list(rect_bot)\n",
    "    rect[0] = rect_top[0]\n",
    "    rect[2] = rect_top[2]\n",
    "    axs[1].set_position(rect)\n",
    "    \n",
    "    # labeling\n",
    "    fig.suptitle('{}\\nrmse: EUR {:.0f}'.format(model_name,rmse), style='italic')\n",
    "    axs[1].set_xlabel('Real price ' + unit, style='italic')\n",
    "    axs[0].set_ylabel('Predicted price\\n' + unit, style='italic')\n",
    "    axs[1].set_ylabel('Prediction error\\n' + unit, style='italic')\n",
    "    \n",
    "    # save\n",
    "    file_name = f\"{RESULTS_DIR}/{model_name.replace(' ','_')}-accuracy.png\"\n",
    "    if True | do_save(file_name): # always save\n",
    "        print(file_name)\n",
    "        with plt.style.context(f\"{cfg['FILE_LOCATION']['app_dir']}/assets/context-paper.mplstyle\"):\n",
    "            plt.savefig(file_name, bbox_inches='tight', transparent=False)\n",
    "    else:\n",
    "        plt.show()\n",
    "        print(f'Skip. {file_name} exists or saving is disabled in settings.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f43c9f9-4fc8-4983-89e5-4bf17272e468",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
