{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abbe95c4-a674-4e8b-a28e-de71fd544e30",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shelve\n",
    "import re\n",
    "import os\n",
    "from predict_price_helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1f7a170-ea87-43ca-b70d-0ecacb1be279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS_DIR\n",
      "def0:\n",
      "do_save = lambda fn: not(os.path.isfile(fn))\n",
      "cfg\n",
      "num_columns\n",
      "cat_columns\n",
      "models\n",
      "df\n"
     ]
    }
   ],
   "source": [
    "with shelve.open('./predict-price.shelve', flag='r') as slf:\n",
    "    for k,v in slf.items():\n",
    "        print(k)\n",
    "        globals()[k] = v\n",
    "        if re.match('def\\d+:', k) is not None:\n",
    "            print(v)\n",
    "            exec(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a104006d-abcc-4e54-967c-dd5bed371182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca603016-fbf2-4495-8d11-9be2569a27fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set figure defaults (needs to be in cell seperate from import sns)\n",
    "plt.style.use([\n",
    "    'default',\n",
    "    f\"{cfg['FILE_LOCATION']['app_dir']}/assets/movshon.mplstyle\",\n",
    "    f\"{cfg['FILE_LOCATION']['app_dir']}/assets/context-notebook.mplstyle\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aca8115-23a4-40c3-a6d5-1250c5e6af75",
   "metadata": {},
   "source": [
    "# Model: MLR with categorical\n",
    "\n",
    "As MLR, but do one-hot-encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7302967c-b928-4d04-9757-74725dfa8a19",
   "metadata": {},
   "source": [
    "Use different scalers for different columns:  \n",
    "https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer_mixed_types.html  \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html#sklearn.compose.ColumnTransformer  \n",
    "p. 68 book: ML with sklearn & tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2db1f6-562d-4e6c-95c7-28ba65ceec14",
   "metadata": {},
   "source": [
    "## Prepare input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcbfd60b-adee-419b-ba11-af5c3826fc1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11214, 29)\n",
      "(11214,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import linear_model\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "model_name = 'MLR with categorical'\n",
    "\n",
    "cat_columns_reduced = list(np.setdiff1d(cat_columns, ['model', 'fuel']))\n",
    "features = num_columns + cat_columns_reduced\n",
    "# Can be reduced here\n",
    "\n",
    "# list of lists with categories. Needed for column transformer\n",
    "cats = list(df[cat_columns_reduced].apply(lambda x:pd.Series(x.unique()).dropna().tolist() + ['missing'], axis='index'))\n",
    "\n",
    "# Use data frame not array\n",
    "yX = df.dropna(subset=['price'])\n",
    "# # only use young\n",
    "# is_yng = yX.age/365.25 < 25\n",
    "# yX = yX[is_yng]\n",
    "X = yX.iloc[:,1:]\n",
    "y = yX.iloc[:,0]\n",
    "X[pd.isna(X)] = np.nan\n",
    "print(X.shape)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d74db39c-d92b-481b-a208-ffab88365f0b",
   "metadata": {},
   "source": [
    "import re\n",
    "\n",
    "# Split fuel helper functions\n",
    "\n",
    "def split_lpg_type(s):\n",
    "    '''Split lpg type from list of fuels separated by / '''\n",
    "    # No type\n",
    "    if s.endswith('lpg'):\n",
    "        return s, ''\n",
    "    if 'lpg' not in s:\n",
    "        return s, ''\n",
    "    # Type is after the last '/'\n",
    "    M = re.search('^(.*)/(.*)$',s)\n",
    "    if M:\n",
    "        return M[1], M[2]\n",
    "    else:\n",
    "        return s, ''\n",
    "\n",
    "def merge_lpg_and_lpgtype(fuel_type):\n",
    "\n",
    "    '''Add LPG type to LPG (remove /). \n",
    "    Note that order of fuels is preserved. I.e. it is able to return both \"benzine/lpg-g3\" and \"lpg-g3/benzine\". '''\n",
    "    \n",
    "    def _lpg_type(s):\n",
    "        return 'lpg-' + split_lpg_type(s)[1] if (type(s) == str) and ('lpg' in s) else ''\n",
    "    def _fuel_type_short(s):\n",
    "        return split_lpg_type(s)[0] if (type(s) == str) else ''\n",
    "\n",
    "    lpg_type = fuel_type.apply(_lpg_type)\n",
    "    #lpg_type = fuel_type.apply(lambda s: 'lpg-' + split_lpg_type(s)[1] if (type(s) == str) and ('lpg' in s) else '')\n",
    "    fuel_type_short = fuel_type.apply(_fuel_type_short)\n",
    "    #fuel_type_short = fuel_type.apply(lambda s: split_lpg_type(s)[0] if (type(s) == str) else '')\n",
    "    fuel_type_new = pd.Series([f.replace('lpg', l) if type(f) == str else f for f,l in zip(fuel_type_short,lpg_type)])\n",
    "    return fuel_type_new\n",
    "\n",
    "def get_unique_fuels(fuel_type):\n",
    "    \n",
    "    '''Splitting fuels at \"/\" and return unique values'''\n",
    "    \n",
    "    def _fuel_type_list(s):\n",
    "        return s.split('/') if type(s) == str else np.nan\n",
    "    \n",
    "    # make list (as string)\n",
    "    fuel_type_list = fuel_type.apply(_fuel_type_list).astype(str)\n",
    "    #fuel_type_list = fuel_type.apply(lambda s:s.split('/') if type(s) == str else np.nan).astype(str)\n",
    "    \n",
    "    # Get unique fuels\n",
    "    possible_fuels = list() # empty list\n",
    "    for l in fuel_type_list.unique():\n",
    "        for ll in eval(l): # use eval to convert str to list\n",
    "            possible_fuels += [ll]     \n",
    "    # uniquify\n",
    "    return np.unique(possible_fuels)\n",
    "\n",
    "    \n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Custom transformer to make one-hot fuel encoder based on string\n",
    "# This is different from get_dummies, because it can take a list of values in a field\n",
    "class DummyfyFuel(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, fuel_names=None):\n",
    "        \n",
    "        assert (fuel_names == None) or (isinstance(fuel_names, (list,))), '[fuel_names] should be list (or None)'\n",
    "        \n",
    "        self.fuel_names = fuel_names\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        \n",
    "        if not self.fuel_names:\n",
    "            # get fuel names based on input.\n",
    "            # Note that if train/test are split, test might lack a fuel type.\n",
    "            self.fuel_names = get_unique_fuels(merge_lpg_and_lpgtype(X))\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \n",
    "        def _fuel_type_list(s):\n",
    "            return s.split('/') if type(s) == str else np.nan\n",
    "        def _fuel_dummies(l):\n",
    "            return int(f in eval(l))\n",
    "        \n",
    "        # get stringyfied list\n",
    "        fuel_type_list = merge_lpg_and_lpgtype(X).apply(_fuel_type_list).astype(str)\n",
    "        #fuel_type_list = merge_lpg_and_lpgtype(X).apply(lambda s:s.split('/') if type(s) == str else np.nan).astype(str)\n",
    "        # set index as input\n",
    "        fuel_type_list.index = X.index\n",
    "\n",
    "        # transform: dummies\n",
    "        fuel_dummies = pd.DataFrame(index=fuel_type_list.index)\n",
    "        for f in self.fuel_names:\n",
    "            fuel_dummies['fuel_' + f] = fuel_type_list.apply(_fuel_dummies)\n",
    "            #fuel_dummies['fuel_' + f] = fuel_type_list.apply(lambda l:int(f in eval(l)))\n",
    "\n",
    "        return fuel_dummies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43bb9b97-3b97-4f56-ae16-d98fe1df2715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7849, 29)\n",
      "(3365, 29)\n"
     ]
    }
   ],
   "source": [
    "# instantiate a dict in models at key with name of this model\n",
    "models[model_name] = dict()\n",
    "\n",
    "# split train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c88f47c7-c105-4da7-a36d-e6919f1835c7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "\n",
    "# Preprocessor: numerical features\n",
    "num_transformer = make_pipeline(\n",
    "    SimpleImputer(strategy='median'),\n",
    "    MinMaxScaler(),\n",
    ")\n",
    "# Preprocessor: categorical features\n",
    "cat_transformer = make_pipeline(\n",
    "    SimpleImputer(strategy='constant', fill_value='missing', missing_values=np.nan),\n",
    "    OneHotEncoder(categories=cats),\n",
    ")\n",
    "\n",
    "# Preprocess: fuels\n",
    "# list of all fuels is passed by using full data set! (X)\n",
    "fuel_list = list(get_unique_fuels(merge_lpg_and_lpgtype(X.fuel)))\n",
    "#fuel_list = ['benzine', 'diesel']\n",
    "get_fuel_dummies = DummyfyFuel(fuel_list)\n",
    "\n",
    "\n",
    "# Combine num and cat\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('numerical', num_transformer, pd.Index(num_columns)),\n",
    "    ('categorical', cat_transformer, pd.Index(cat_columns_reduced)),\n",
    "    ('onehot_fuel', get_fuel_dummies, 'fuel')\n",
    "], verbose=True)\n",
    "\n",
    "# full pipeline with preproc and mlr\n",
    "mlr = make_pipeline(\n",
    "    preprocessor,\n",
    "    linear_model.LinearRegression()\n",
    ")\n",
    "\n",
    "# Target transformation: log transform price\n",
    "def _pow10(y):\n",
    "    return 10**y\n",
    "pl = TransformedTargetRegressor(\n",
    "    regressor=mlr,\n",
    "    func=np.log10,\n",
    "    inverse_func=pow10,\n",
    "#    inverse_func=lambda y: 10**y,\n",
    "#     func=lambda x:x,\n",
    "#     inverse_func=lambda y: y,\n",
    "#     inverse_func=np.exp,\n",
    ")\n",
    "\n",
    "models[model_name].update({'model':pl})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca8df88b-8593-4202-bef8-91e53847a1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ColumnTransformer] ..... (1 of 3) Processing numerical, total=   0.0s\n",
      "[ColumnTransformer] ... (2 of 3) Processing categorical, total=   0.0s\n",
      "[ColumnTransformer] ... (3 of 3) Processing onehot_fuel, total=   0.5s\n"
     ]
    }
   ],
   "source": [
    "# fit\n",
    "pl.fit(X_train, y_train)\n",
    "y_pred = pl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3949e72f-fd1e-4956-be22-2a36bcf65efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ColumnTransformer] ..... (1 of 3) Processing numerical, total=   0.0s\n",
      "[ColumnTransformer] ... (2 of 3) Processing categorical, total=   0.0s\n",
      "[ColumnTransformer] ... (3 of 3) Processing onehot_fuel, total=   0.2s\n",
      "[ColumnTransformer] ..... (1 of 3) Processing numerical, total=   0.0s\n",
      "[ColumnTransformer] ... (2 of 3) Processing categorical, total=   0.0s\n",
      "[ColumnTransformer] ... (3 of 3) Processing onehot_fuel, total=   0.2s\n",
      "[ColumnTransformer] ..... (1 of 3) Processing numerical, total=   0.0s\n",
      "[ColumnTransformer] ... (2 of 3) Processing categorical, total=   0.0s\n",
      "[ColumnTransformer] ... (3 of 3) Processing onehot_fuel, total=   0.2s\n",
      "[ColumnTransformer] ..... (1 of 3) Processing numerical, total=   0.0s\n",
      "[ColumnTransformer] ... (2 of 3) Processing categorical, total=   0.0s\n",
      "[ColumnTransformer] ... (3 of 3) Processing onehot_fuel, total=   0.2s\n",
      "[ColumnTransformer] ..... (1 of 3) Processing numerical, total=   0.0s\n",
      "[ColumnTransformer] ... (2 of 3) Processing categorical, total=   0.0s\n",
      "[ColumnTransformer] ... (3 of 3) Processing onehot_fuel, total=   0.2s\n"
     ]
    }
   ],
   "source": [
    "# sanity check that target transformation has occured as expected\n",
    "# y_pred_manual_transform = mlr.predict(X_test)\n",
    "# assert all(np.log10(y_pred)-y_pred_manual_transform == 0)\n",
    "\n",
    "models[model_name].update({'n':y.shape[0]})\n",
    "models[model_name].update({'n features':X.shape[1]})\n",
    "\n",
    "# parameters\n",
    "betas = [pl.regressor_.steps[-1][1].intercept_, *pl.regressor_.steps[-1][1].coef_]\n",
    "models[model_name].update({'betas':betas})\n",
    "\n",
    "# score\n",
    "models[model_name].update({'R^2':pl.score(X,y)})\n",
    "models[model_name].update({'test R^2':pl.score(X_test,y_test)})\n",
    "cv_results = cross_val_score(pl, X_test, y_test, cv=5)\n",
    "models[model_name].update({'cv R^2':cv_results})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f904df8-7fdf-4bef-98cd-45038ba43714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update features, by adding fuels\n",
    "cat_columns_reduced += ['fuel']\n",
    "cats += [fuel_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b7bf93b-8d58-4c54-bed6-7682b18d57be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split betas per category feature.\n",
    "idx_start = len(num_columns)+1\n",
    "cat_betas = list()\n",
    "for cat in cats:\n",
    "    cat_betas += [betas[idx_start:idx_start+len(cat)]]\n",
    "    idx_start += len(cat)\n",
    "# Check if all betas are stored\n",
    "assert cat_betas[0][0] == betas[len(num_columns)+1] # first cat beta follows numerical betas \n",
    "assert cat_betas[-1][-1] == betas[-1] # last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7b94a4b-a1c5-4bf6-955d-d731d9c24119",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove_when_contains:image"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tom/bin/satdatsci/Saturday-Datascience/results/MLR_with_categorical.png\n"
     ]
    }
   ],
   "source": [
    "# plot coefficients\n",
    "\n",
    "# plot numerical and catagorical in different subplots\n",
    "n_plots = len(cat_columns_reduced) + 1\n",
    "fig,axs=plt.subplots(\n",
    "    nrows=n_plots,\n",
    "    figsize=[16,4*n_plots]\n",
    ")\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "\n",
    "# Plot numerical\n",
    "ax = axs[0]\n",
    "# sorted bar height\n",
    "betas = models[model_name]['betas']\n",
    "num_betas = betas[1:len(num_columns)+1]\n",
    "x = ['offset'] + [features[i] for i in np.argsort(num_betas)[::-1]]\n",
    "y = [betas[0]] + sorted(num_betas, reverse=True)\n",
    "\n",
    "# plot bar\n",
    "ax.bar(x=x, height=y, edgecolor='k', facecolor='None', clip_on=True)\n",
    "\n",
    "# add values when bar is small\n",
    "for x_val, coef in zip(x,y):\n",
    "    if np.abs(coef)<0.5:\n",
    "        ax.text(x_val, coef, '{:.3g}'.format(coef), rotation=45, va='bottom', ha='left')\n",
    "ax.set_yticks(np.arange(-2,2.2,0.5))\n",
    "ax.set_ylim(top=+2, bottom=-2)\n",
    "# offset\n",
    "x_val = x[0]\n",
    "coef = y[0]\n",
    "ax.text(x_val, 2, '{:.3g}'.format(coef), rotation=45, va='bottom', ha='left')\n",
    "\n",
    "# plot origin\n",
    "x_sign_switch = np.nonzero(np.array(y) < 0)[0][0]\n",
    "ax.axvline(x_sign_switch-0.5, linewidth=2, linestyle='--', color='k')\n",
    "ax.axhline(0, linewidth=2, linestyle='-', color='k')\n",
    "\n",
    "# labels        \n",
    "rot = 45\n",
    "fsz = 10\n",
    "ha = 'right'\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels=x, rotation=rot, va='top', ha=ha, style='italic', fontsize=fsz)\n",
    "ax.xaxis.set_tick_params(which='minor', bottom=False)\n",
    "ax.set_ylabel('Coefficient (a.u.)', style='italic')\n",
    "ax.set_title('Multiple linear regression\\nNumerical features', style='italic') \n",
    "\n",
    "# stats\n",
    "xy=[ax.get_xlim()[1], ax.get_ylim()[1]]\n",
    "ax.text(xy[0]*1.05,xy[1], '$R^2$ = {:.2f}, $R^2_{{cv{:g}}}$ = {:.2f} (+/-{:.2f})'.format(\n",
    "    models[model_name]['R^2'],\n",
    "    models[model_name]['cv R^2'].shape[0],\n",
    "    np.mean(models[model_name]['cv R^2']),\n",
    "    np.std(models[model_name]['cv R^2']),\n",
    ") + '\\n' +\n",
    "         'train (n = {})'.format(y_train.shape[0]) + '\\n' +\n",
    "         'test (n = {}, $R^2$ = {:.2f})'.format(\n",
    "             y_test.shape[0],\n",
    "             models[model_name]['test R^2'],\n",
    "         ), style='italic', va='top', ha='left')\n",
    "\n",
    "# Plot categorical\n",
    "for cat, cat_beta, cat_name, ax in zip(cats, cat_betas, cat_columns_reduced, axs[1:]):\n",
    "    # sort by height\n",
    "    x = [cat[i] for i in np.argsort(cat_beta)[::-1]]\n",
    "    y = sorted(cat_beta, reverse=True)\n",
    "    #x = cat\n",
    "    #y = cat_beta\n",
    "    # plot bar\n",
    "    ax.bar(x=x, height=y, edgecolor='k', facecolor='None', clip_on=False)\n",
    "\n",
    "    # prettify\n",
    "    ax.set_yticks(np.arange(-1,+1.1,0.2))\n",
    "    ax.set_ylim(top=+1, bottom=-1)\n",
    "\n",
    "    # plot origin\n",
    "    x_sign_switch = np.nonzero(np.array(y) < 0)[0][0]\n",
    "    ax.axvline(x_sign_switch-0.5, linewidth=2, linestyle='--', color='k')\n",
    "    ax.axhline(0, linewidth=2, linestyle='-', color='k')\n",
    "\n",
    "    # labels\n",
    "    rot = 45\n",
    "    fsz = 10\n",
    "    ha = 'right'\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(labels=x, rotation=rot, va='top', ha=ha, style='italic', fontsize=fsz)\n",
    "    ax.xaxis.set_tick_params(which='minor', bottom=False)\n",
    "    ax.set_title('Categorical feature: ' + cat_name, style='italic')\n",
    "    ax.set_ylabel('Coefficient (a.u.)', style='italic')\n",
    "    # add extra margin if bars are too wide (too little bars)\n",
    "    if len(x) < 20:\n",
    "        add_space = len(x) - 20\n",
    "        xl = list(ax.set_xlim())\n",
    "        xl[1] -= add_space/2\n",
    "        xl[0] += add_space/2\n",
    "        ax.set_xlim(xl)\n",
    "\n",
    "# Label on bottom panel\n",
    "ax = axs[-1]\n",
    "ax.set_xlabel('Sorted features', style='italic')\n",
    "\n",
    "# Save\n",
    "file_name = f\"{RESULTS_DIR}/{model_name.replace(' ','_')}.png\"\n",
    "if True | do_save(file_name): # always save\n",
    "    print(file_name)\n",
    "    with plt.style.context(f\"{cfg['FILE_LOCATION']['app_dir']}/assets/context-paper.mplstyle\"):\n",
    "        plt.savefig(file_name, bbox_inches='tight', transparent=False)\n",
    "else:\n",
    "    plt.show()\n",
    "    print(f'Skip. {file_name} exists or saving is disabled in settings.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "543e2e9c-4362-44ea-8e5e-9a375002175d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shelve file [./predict-price.shelve] contains models:\n",
      "\tlinear regression no cv\n",
      "\tlinear regression log price young\n",
      "\tMLR reduced observations\n",
      "\tMLR impute median\n",
      "\tMLR with categorical\n"
     ]
    }
   ],
   "source": [
    "fn = './predict-price.shelve'\n",
    "with shelve.open(fn, flag='w') as slf:\n",
    "    slf['models'] = models \n",
    "    print(f'Shelve file [{fn}] contains models:')\n",
    "    for m in slf['models'].keys():\n",
    "        print(f'\\t{m}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
